{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_T2H(dep):\n",
    "    '''\n",
    "    根据依存树构建每个词的发射字典\n",
    "    txt: 设备机房、电梯机房、水箱间、天线\n",
    "    dep: [\n",
    "        (1, 2, 'ATT'), (2, 0, 'HED'), (3, 5, 'WP'), \n",
    "        (4, 5, 'ATT'), (5, 2, 'COO'), (6, 7, 'WP'), \n",
    "        (7, 2, 'COO'), (8, 9, 'WP'), (9, 2, 'COO')\n",
    "    ]\n",
    "    return {\n",
    "        2: {'ATT': [1], 'COO': [5, 7, 9]}, \n",
    "        0: {'HED': [2]}, \n",
    "        5: {'ATT': [4]}\n",
    "    }\n",
    "    '''\n",
    "    dep_T2H = defaultdict(dict)\n",
    "    for d in dep:\n",
    "        # if d[2] in ['WP','LAD']: continue\n",
    "        if d[1] in dep_T2H:\n",
    "            dep_T2H[d[1]][d[2]] = dep_T2H[d[1]].get(d[2],[])+[d[0]]\n",
    "        else:\n",
    "            dep_T2H[d[1]] = {d[2]:[d[0]]}\n",
    "    return dep_T2H\n",
    "    \n",
    "def find_smallest(dep_T2H, p):\n",
    "    '''\n",
    "    寻找当前中心语的修饰覆盖的范围\n",
    "    由于不存在交叉的情况，所以只要往前找最小的即可\n",
    "    return: 第一个词对应的位置\n",
    "    '''\n",
    "    if p==0: return 1\n",
    "    p_out = list(dep_T2H.get(p,{}).values())\n",
    "    p_out = list(chain(*p_out))\n",
    "    if not p_out or min(p_out)>p: return p\n",
    "    smallest = find_smallest(dep_T2H, min(p_out))\n",
    "    return smallest\n",
    "\n",
    "def find_biggest(dep_T2H, p):\n",
    "    '''\n",
    "    寻找当前中心语的修饰覆盖的范围\n",
    "    由于不存在交叉的情况，所以只要往前找最小的即可\n",
    "    return: 第一个词对应的位置\n",
    "    '''\n",
    "    p_out = list(dep_T2H.get(p,{}).values())\n",
    "    p_out = list(chain(*p_out))\n",
    "    if not p_out or max(p_out)<p: return p\n",
    "    biggest = find_biggest(dep_T2H, max(p_out))\n",
    "    return biggest\n",
    "\n",
    "ltp = LTP('LTP/small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把模型分词错误的地方替换为可以正确分词的内容\n",
    "replace_dic = {'压强': '压力'}\n",
    "\n",
    "ltp.add_words(words=list(replace_dic.keys()), freq=2)\n",
    "\n",
    "def deal_miss_word(txt, replace_dic):\n",
    "    '''将分词错误的地方替换为可以正确分词的内容'''\n",
    "    words = ltp.pipeline([txt], tasks = [\"cws\"]).cws[0]\n",
    "    recover_dic = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in replace_dic:\n",
    "            recover_dic[i] = words[i]\n",
    "            words[i] = replace_dic[words[i]]\n",
    "    return ''.join(words), recover_dic\n",
    "\n",
    "def span_contain(span1, span2):\n",
    "    '''span1是否包含span2'''\n",
    "    if span1[0]<=span2[0] and span1[1]>=span2[1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def del_intra_span(phrase_span):\n",
    "    '''去掉被其他span包围的span'''\n",
    "    if not phrase_span: return phrase_span\n",
    "    merge_span = [phrase_span[-1]]\n",
    "    for i in range(len(phrase_span)-2, -1, -1):\n",
    "        cur_span = phrase_span[i]\n",
    "        if not span_contain(merge_span[-1], cur_span):\n",
    "        # if (cur_span[0]-merge_span[-1][0])*(merge_span[-1][1]-cur_span[1])<0:\n",
    "            merge_span.append(cur_span)\n",
    "    merge_span.reverse()\n",
    "    return merge_span\n",
    "\n",
    "def del_inter_span(lst1, lst2):\n",
    "    '''只保留span1中没有被span2中元素完全覆盖的部分'''\n",
    "    i, j = 0, 0\n",
    "    len1, len2 = len(lst1), len(lst2)\n",
    "    del_idx = []\n",
    "    while i<len1 and j<len2:\n",
    "        if span_contain(lst2[j], lst1[i]):\n",
    "            del_idx.append(i)\n",
    "            i += 1\n",
    "            continue\n",
    "        # if lst1[i][1]<=lst2[j][0]: i+=1\n",
    "        if lst2[j][1]<=lst1[i][0]: j += 1\n",
    "        else: i += 1\n",
    "    lst = [lst1[i] for i in range(len1) if i not in del_idx]\n",
    "    return lst\n",
    "\n",
    "\n",
    "'''\n",
    "node-edge-node\n",
    "node-edge-tri\n",
    "tri-edge-tri\n",
    "'''\n",
    "class Trip:\n",
    "    def __init__(self, head, rel, tail):\n",
    "        '''\n",
    "        mode: 元素的表达形式\n",
    "            span表示起止范围，如[2,5]；\n",
    "            str表示字符串，如'灭火器'\n",
    "        '''\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "        self.tail = tail\n",
    "        # self.val = '[{}-{}-{}]'.format(\n",
    "        #     head[1], rel[1], tail[1]\n",
    "        # )\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "def have_dep(idx, tag, dep, dep_T2H):\n",
    "    '''判断当前词是否做对应成分'''\n",
    "    f1 = tag in dep_T2H[idx+1]\n",
    "    f2 = False\n",
    "    if dep[idx][2] == 'COO':\n",
    "        f2 = have_dep(dep[idx][1]-1, tag, dep, dep_T2H)\n",
    "    return f1 or f2\n",
    "\n",
    "def get_all_coo(idx, dep_T2H):\n",
    "    '''按照在序列中出现的顺序得到和当前词并列的所有词'''\n",
    "    c1 = dep_T2H[idx+1].get('COO', [])\n",
    "    c2 = []\n",
    "    for c in c1:\n",
    "        c2.append(c)\n",
    "        c2 += get_all_coo(c-1, dep_T2H)\n",
    "    return c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "b = {1:2}\n",
    "a.update(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('施工', 'v', (1, 0, 'HED')), ('临时', 'b', (2, 3, 'ADV')), ('办公', 'v', (3, 23, 'ATT')), ('与', 'c', (4, 6, 'LAD')), ('生活', 'v', (5, 6, 'ATT')), ('用房', 'n', (6, 3, 'COO')), ('、', 'wp', (7, 9, 'WP')), ('发电机', 'n', (8, 9, 'ATT')), ('房', 'n', (9, 3, 'COO')), ('、', 'wp', (10, 9, 'WP')), ('变配电站', 'v', (11, 9, 'ATT')), ('、', 'wp', (12, 19, 'WP')), ('厨房', 'n', (13, 14, 'ATT')), ('操作间', 'n', (14, 19, 'ATT')), ('、', 'wp', (15, 16, 'WP')), ('锅炉房', 'n', (16, 19, 'COO')), ('和', 'c', (17, 19, 'LAD')), ('可燃', 'i', (18, 19, 'ATT')), ('材料', 'n', (19, 3, 'COO')), ('与', 'c', (20, 22, 'LAD')), ('易燃易爆', 'i', (21, 22, 'ATT')), ('物品', 'n', (22, 19, 'COO')), ('库房', 'n', (23, 1, 'VOB')), ('，', 'wp', (24, 1, 'WP')), ('当', 'p', (25, 38, 'ADV')), ('采用', 'v', (26, 30, 'ATT')), ('金属', 'n', (27, 28, 'ATT')), ('夹芯', 'v', (28, 29, 'ATT')), ('板材', 'n', (29, 26, 'VOB')), ('时', 'n', (30, 25, 'POB')), ('，', 'wp', (31, 25, 'WP')), ('其', 'r', (32, 33, 'ATT')), ('芯材', 'n', (33, 36, 'ATT')), ('的', 'u', (34, 33, 'RAD')), ('燃烧', 'v', (35, 36, 'ATT')), ('性能', 'n', (36, 38, 'SBV')), ('应', 'v', (37, 38, 'ADV')), ('为', 'v', (38, 1, 'COO')), ('A', 'm', (39, 40, 'ATT')), ('级', 'q', (40, 38, 'VOB')), ('。', 'wp', (41, 1, 'WP'))]\n",
      "71 self.dep_T2H defaultdict(<class 'dict'>, {0: {'HED': [1]}, 3: {'ADV': [2], 'COO': [6, 9, 19]}, 23: {'ATT': [3]}, 6: {'LAD': [4], 'ATT': [5]}, 9: {'WP': [7, 10], 'ATT': [8, 11]}, 19: {'WP': [12], 'ATT': [14, 18], 'COO': [16, 22], 'LAD': [17]}, 14: {'ATT': [13]}, 16: {'WP': [15]}, 22: {'LAD': [20], 'ATT': [21]}, 1: {'VOB': [23], 'WP': [24, 41], 'COO': [38]}, 38: {'ADV': [25, 37], 'SBV': [36], 'VOB': [40]}, 30: {'ATT': [26]}, 28: {'ATT': [27]}, 29: {'ATT': [28]}, 26: {'VOB': [29]}, 25: {'POB': [30], 'WP': [31]}, 33: {'ATT': [32], 'RAD': [34]}, 36: {'ATT': [33, 35]}, 40: {'ATT': [39]}})\n",
      "noun phrases [['临时', '办公', '与', '生活', '用房', '、', '发电机', '房', '、', '变配电站', '、', '厨房', '操作间', '、', '锅炉房', '和', '可燃', '材料', '与', '易燃易爆', '物品', '库房'], ['金属', '夹芯', '板材'], ['其', '芯材', '的', '燃烧', '性能'], ['A', '级']]\n",
      "adv phrases [['临时'], ['当', '采用', '金属', '夹芯', '板材', '时'], ['应']]\n",
      "preda phrases [['施工'], ['采用'], ['为']]\n",
      "132 [1, 38]\n",
      "135 [1, 38] [[1, 1], [38, 38]]\n",
      "510 [[1, 1], [38, 38]]\n",
      "noun phrases [['易燃易爆', '物品', '库房'], ['当', '采用', '金属', '夹芯', '板材', '时', '，', '其', '芯材', '的', '燃烧', '性能']]\n",
      "noun phrases [['临时', '办公', '与', '生活', '用房', '、', '发电机', '房', '、', '变配', '电站', '、', '厨房', '操作间', '、', '锅炉房', '和', '可燃', '材料']]\n",
      "[[None, [1, 1, 'node'], [2, 23, 'node']], [[32, 36, 'node'], [38, 38, 'node'], [39, 40, 'node']]]\n",
      "single trip phrases [[[], ['施工'], ['临时', '办公', '与', '生活', '用房', '、', '发电机', '房', '、', '变配电站', '、', '厨房', '操作间', '、', '锅炉房', '和', '可燃', '材料', '与', '易燃易爆', '物品', '库房']], [['其', '芯材', '的', '燃烧', '性能'], ['为'], ['A', '级']]]\n",
      "[[None, [1, 1, 'node'], [2, 23, 'node']], [[32, 36, 'node'], [38, 38, 'node'], [39, 40, 'node']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None, [1, 1, 'node'], [2, 23, 'node']],\n",
       " [[32, 36, 'node'], [38, 38, 'node'], [39, 40, 'node']]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from KPR import get_so\n",
    "\n",
    "class RuleNER:\n",
    "    '''\n",
    "    用规则系统做NER\n",
    "    基本上所有以名词为中心语的短语都可以当作实体先抽出来\n",
    "    '''\n",
    "    def __init__(self, ltp) -> None:\n",
    "        self.ltp = ltp\n",
    "    \n",
    "    def get_spd(self, txt):\n",
    "        txt, recover_dic = deal_miss_word(txt, replace_dic)\n",
    "        result = self.ltp.pipeline([txt], tasks = [\"cws\",\"dep\",\"pos\"])\n",
    "        seg = result.cws[0]\n",
    "        pos = result.pos[0]\n",
    "        dep = result.dep[0]\n",
    "        for key in recover_dic:\n",
    "            seg[key] = recover_dic[key]\n",
    "        dep = list(zip(range(1,1+len(seg)), dep['head'], dep['label']))\n",
    "        return seg, pos, dep\n",
    "\n",
    "    def get_full_trips(self, txt, offset=0):\n",
    "        '''得到扩展三元组'''\n",
    "        seg, pos, dep = self.get_spd(txt)\n",
    "        dep_T2H = build_T2H(dep)   # 构建发射字典\n",
    "        print('71 self.dep_T2H', dep_T2H)\n",
    "        so_spans = self.get_so(seg, pos, dep, dep_T2H)\n",
    "        adv_spans = self.get_adv(seg, pos, dep, dep_T2H)\n",
    "        preda_spans = self.get_preda(seg, pos, dep, dep_T2H)\n",
    "\n",
    "        idx_so_span = {}\n",
    "        idx_uncon_so_span = {}\n",
    "        idx_preda_span = {}\n",
    "        for span in so_spans:\n",
    "            idx_so_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        # for span in uncon_so_spans:\n",
    "        #     idx_uncon_so_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        for span in preda_spans:\n",
    "            idx_preda_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        head = list(dep_T2H[0].values())[0][0]\n",
    "        hed_list = [head] + get_all_coo(head-1, dep_T2H)\n",
    "        ########## 要处理解析结果中没有谓语的情况 ##########\n",
    "        # 相对密度不小于0.75的可燃气体\n",
    "        print('132', hed_list)\n",
    "        hed_spans = [idx_preda_span[i] for i in hed_list]\n",
    "        hed_spans = del_intra_span(hed_spans)\n",
    "        print('135', hed_list, hed_spans)\n",
    "        # hed_spans = []\n",
    "        # for i in hed_list:\n",
    "        #     if idx_preda_span[i] not in hed_spans:\n",
    "        #         hed_spans.append(idx_preda_span[i])\n",
    "        single_trips = self.get_single_trips(\n",
    "            seg, pos, dep, dep_T2H, hed_spans, idx_preda_span, \n",
    "            idx_so_span, idx_uncon_so_span\n",
    "        )\n",
    "        \n",
    "        def shift_offset(spans):\n",
    "            '''递归得到字符串'''\n",
    "            spans_shift = []\n",
    "            for s in spans:\n",
    "                # print('414', s)\n",
    "                # if len(s)==3:\n",
    "                if not s:\n",
    "                    span_str = None\n",
    "                elif s[-1]=='tri':\n",
    "                    span_str = shift_offset(s[:-1])\n",
    "                    span_str.append('tri')\n",
    "                elif s[-1]!='node':\n",
    "                    span_str = shift_offset(s)\n",
    "                else:\n",
    "                    span_str = [s[0]+offset, s[1]+offset]\n",
    "                    span_str.append('node')\n",
    "                spans_shift.append(span_str)\n",
    "            return spans_shift\n",
    "        \n",
    "        single_trips = [\n",
    "            shift_offset(single_trip) for single_trip in single_trips\n",
    "        ]\n",
    "        # print('154', single_trips)\n",
    "        return single_trips\n",
    "\n",
    "    def get_so(self, seg, pos, dep, dep_T2H):\n",
    "        '''抽取简单主语和、宾语和谓语'''\n",
    "\n",
    "        def is_skip_word(idx):\n",
    "            '''判断当前词是否需要被跳过'''\n",
    "            # 状语，设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道；\n",
    "            # 不是方位名词时基本是条件状语，不适合以此为中心语提取短语\n",
    "            # 在温度大于100时，加油站应设在供应站和调压站、加油站；当地铁站位于道路下方，加油站应设在供应站和调压站、加油站\n",
    "            # if dep[i][2]=='POB' and pos[i]!='nd': continue\n",
    "            # 在体育馆内部，体育场要打开抽湿器，关闭加热器\n",
    "            # 当温度大于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "            f1 = dep[idx][2]=='ADV'\n",
    "            f2 = False\n",
    "            f3 = False\n",
    "            # f4 = idx>0 and seg[idx-1]=='的'\n",
    "            if dep[idx][2]=='POB':                              # 介宾短语中宾语的修饰语有主谓结构：当温度大于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "                att_idx = dep_T2H[idx+1].get('ATT', [-1])[0]\n",
    "                for tag in ['SBV','FOB','VOB']:\n",
    "                    if tag in dep_T2H[att_idx]:\n",
    "                        f2 = True\n",
    "                        break\n",
    "            for tag in ['SBV','FOB','VOB']:                     # 谓语不可能是主宾语的中心词：当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器\n",
    "                if have_dep(idx, tag, dep, dep_T2H):\n",
    "                    f3 = True\n",
    "                    break\n",
    "            # print('160', seg[idx], f4, (f1 or f2 or f3)==((f1 or f2 or f3) and not f4))\n",
    "            # print(f1 or f2 or f3, (f1 or f2 or f3) and not f4)\n",
    "            # return f1 or f2 or f3\n",
    "            return f1 or f2 or f3\n",
    "        \n",
    "        def is_anchor_word(idx):\n",
    "            '''判断当前词是否可以当作锚点'''\n",
    "            f1 = 'n' in pos[idx] or pos[idx] in ['m', 'q']      # 数词和量词可以当中心点：应根据本规范第2.1节进行合规性判定。\n",
    "            f2 = dep[idx][2] in ['SBV','FOB','VOB']\n",
    "            f3 = False\n",
    "            f4 = idx>0 and seg[idx-1]=='的'                     # 前面是“的”则认为该词可以做中心语：本规范适用于新建、扩建、改建的民用与工业建筑中自动喷水灭火系统的设计。\n",
    "            if dep[idx][2]=='COO':\n",
    "                f3 = is_anchor_word(dep[idx][1]-1)\n",
    "            return f1 or f2 or f3 or f4\n",
    "\n",
    "        # def is_concat_word(idx, anchor_list):\n",
    "        #     '''\n",
    "        #     如果当前词的COO能链接到上一个span，则合并\n",
    "        #     '''\n",
    "        #     f1 = dep[i][2]=='COO'\n",
    "        #     print('146', idx, dep[idx], anchor_list)\n",
    "        #     if dep[idx][1] in anchor_list:\n",
    "        #         anchor_list.append(idx+1)\n",
    "        #         return True\n",
    "        #     return False\n",
    "\n",
    "        def is_concat_word(idx, pre_span):\n",
    "            '''\n",
    "            如果当前词的COO能链接到上一个span，则合并\n",
    "            '''\n",
    "            f1 = dep[idx][2]=='COO'\n",
    "            f2 = pre_span and pre_span[0]<=dep[idx][1]<=pre_span[1]\n",
    "            return f1 and f2\n",
    "\n",
    "        # seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        # dep_T2H = self.dep_T2H\n",
    "        phrase_span = [[]]\n",
    "        uncon_so_spans = []\n",
    "        for i in range(len(pos)):\n",
    "            if is_skip_word(i): continue\n",
    "            # if 'n' in pos[i] or dep[i][2] in ['SBV','FOB','VOB']:\n",
    "            if is_anchor_word(i):\n",
    "                start = find_smallest(dep_T2H, i+1)\n",
    "                while True:                                                 # 在找当前范围的同时判断之前的是否被覆盖\n",
    "                    if phrase_span[-1] and start<=phrase_span[-1][0]:\n",
    "                        phrase_span.pop()\n",
    "                        uncon_so_spans.pop()\n",
    "                    else:\n",
    "                        break\n",
    "                uncon_so_spans.append([start, i+1])\n",
    "                if is_concat_word(i, phrase_span[-1]):\n",
    "                    start = phrase_span[-1][0]\n",
    "                    phrase_span.pop()\n",
    "                phrase_span.append([start, i+1])\n",
    "        phrase_span = phrase_span[1:]\n",
    "        # print('phrase_span', [seg[s[0]-1:s[1]] for s in phrase_span])\n",
    "        # merge_span = del_intra_span(phrase_span)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in phrase_span]\n",
    "        print('noun phrases', phrases)\n",
    "        # print(uncon_so_spans)\n",
    "        # uncon_phrases = [seg[s[0]-1:s[1]] for s in uncon_so_spans]\n",
    "        # print('uncon noun phrases', uncon_phrases)\n",
    "        # return phrase_span, uncon_so_spans\n",
    "        return phrase_span\n",
    "    \n",
    "    def get_adv(self, seg, pos, dep, dep_T2H):\n",
    "        '''\n",
    "        抽取状语\n",
    "        状中结构，从中心语向前找\n",
    "        介宾结构，从介词向后找\n",
    "        '''\n",
    "        # seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        # dep_T2H = self.dep_T2H\n",
    "        phrase_span = []\n",
    "        for i in range(len(pos)):\n",
    "            if dep[i][2]=='ADV':\n",
    "                # 状中结构ADV确定状语结束位置：当温度大于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "                start = find_smallest(dep_T2H, i+1)\n",
    "                end = dep_T2H[i+1].get('POB', [i+1])[0]\n",
    "                phrase_span.append([start, end])\n",
    "            elif dep[i][2]=='POB' and dep[dep[i][1]-1]=='ADV':\n",
    "                # 介宾短语POB确定状语的结束位置：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "                phrase_span.append([dep[i][1], i+1])\n",
    "        merge_span = del_intra_span(phrase_span)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        print('adv phrases', phrases)\n",
    "        return merge_span\n",
    "\n",
    "    def get_preda(self, seg, pos, dep, dep_T2H):\n",
    "        '''\n",
    "        像SO一样抽取所有的谓词，在三元组抽取中，用HED及其并列位置借助字典进行映射\n",
    "        抽取谓词，没有处理主语从句、定语从句的谓词\n",
    "        句子的核心词及其并列词，且是动词或介词\n",
    "        是动词时需要将补语算作谓词的一部分\n",
    "        介词做谓语：仓库应在居住区外部\n",
    "        补语结构：仓库应设在居住区外部\n",
    "        '''\n",
    "        # 0: {'HED': [20]}\n",
    "        def is_concat_preda(i, pre_span):\n",
    "            '''\n",
    "            谓词合并需要满足三个条件\n",
    "            f1：连词直接连到上一个span后面\n",
    "            f2：当前谓词跟上一个span的谓词是并列关系\n",
    "            f3：当前谓词没有直接相连的FOB或SBV\n",
    "            样例：\n",
    "                仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "                当温度大于或明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "            '''\n",
    "            # f1 = seg[i-2]=='、' or dep_T2H[i].get('LAD', [-2])[0]==i-1\n",
    "            # print('245', i, dep[i-1], pre_span, dep[i-1][1]==pre_span[0])\n",
    "            # f1 = seg[i-2]=='、' or dep_T2H[i].get('LAD', [-2])[0]==pre_span[-1]+1\n",
    "            # f2 = dep[i-1][1]==pre_span[0]\n",
    "            # f3 = 'SBV' not in dep_T2H[i] and 'FOB' not in dep_T2H[i]\n",
    "            # return i>1 and f1 and f2 and f3\n",
    "            if not pre_span: return False\n",
    "            f1 = seg[i-1]=='、' or dep_T2H[i+1].get('LAD', [-2])[0]==pre_span[-1]+1\n",
    "            f1 = f1 or dep[i][0]-dep[i][1]==1                                           # 跟上一个动词连续并列：在建筑防火中贯彻执行国家技术经济政策\n",
    "            f2 = dep[i][1]==pre_span[0]\n",
    "            f3 = 'SBV' not in dep_T2H[i+1] and 'FOB' not in dep_T2H[i+1]\n",
    "            return i>0 and f1 and f2 and f3\n",
    "\n",
    "        phrase_span = [[]]\n",
    "        for i in range(len(pos)):\n",
    "            f1 = False\n",
    "            for tag in ['SBV','FOB','VOB']:\n",
    "                if have_dep(i, tag, dep, dep_T2H):\n",
    "                    f1 = True\n",
    "                    break\n",
    "            f2 = pos[i]!='a'\n",
    "            f3 = pos[i]=='a' and dep_T2H[i+1].get('SBV',[-1])[0]!=i\n",
    "            if f1 and (f2 or f3):\n",
    "                start = i + 1\n",
    "                # 动词带有补语其表意才完整：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "                end = dep_T2H.get(i+1).get('CMP', [i+1])[0]\n",
    "                if dep[i][2]=='COO' and is_concat_preda(i, phrase_span[-1]):\n",
    "                    start = phrase_span[-1][0]\n",
    "                    phrase_span.pop()\n",
    "                phrase_span.append([start, end])\n",
    "        phrase_span = phrase_span[1:]\n",
    "\n",
    "        # phrase_span = []\n",
    "        # head = dep_T2H[0]['HED'][0]\n",
    "        # # preda_list = [head] + dep_T2H.get(head,{}).get('COO',[])\n",
    "        # preda_list = [head] + get_all_coo(head-1, dep_T2H)\n",
    "        # for i in preda_list:\n",
    "        #     if pos[i-1] in ['v','p']:\n",
    "        #         start = i\n",
    "        #         # 动词带有补语其表意才完整：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "        #         end = dep_T2H.get(i, {}).get('CMP', [i])[0]\n",
    "        #         if dep[i-1][2]=='COO' and is_concat_preda(i, phrase_span[-1]):\n",
    "        #             start = phrase_span[-1][0]\n",
    "        #             phrase_span.pop()\n",
    "        #         phrase_span.append([start, end])\n",
    "\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in phrase_span]\n",
    "        print('preda phrases', phrases)\n",
    "        # merge_span = del_intra_span(phrase_span)\n",
    "        # phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        # print('preda merge_span', phrases)\n",
    "        return phrase_span\n",
    "    \n",
    "    def bi_subj(self, preda, seg, pos):\n",
    "        '''\n",
    "        处理双主语结构的句子\n",
    "        看似没有宾语，但实际上是两个主语发生这个动作\n",
    "        也会出现在定语从句、主语从句中\n",
    "        满足判定条件则返回双主语构成的三元组\n",
    "            谓语在句子最后，且要对谓词分类，把谓词出现在句尾的拿出来，标一下分类数据\n",
    "            连词和谓语之间是一个完整的名词短语\n",
    "            连词之前的词属于一个名词短语\n",
    "        样例：\n",
    "        瓶装液化石油气不应跟其他化学危险物品混放；\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触能引起燃烧的场所\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触能引起燃烧\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触    短语的合并需要打补丁\n",
    "        '''\n",
    "        ########## 需要根据谓词类别判断是双主语还是单主语 ##########\n",
    "        f1 = preda[-1]==len(pos) or pos[preda[-1]]=='wp'        # 谓语在句子最后\n",
    "        f2 = False\n",
    "        f3 = False\n",
    "        for i in range(preda[0]-1, -1, -1):\n",
    "            if seg[i] in '与和跟': break\n",
    "        if i>0:\n",
    "            # 连词和谓语之间是一个完整的名词短语\n",
    "            txt = ''.join(seg[i+1:preda[0]-1])\n",
    "            seg1, pos1, dep1 = self.get_spd(txt)\n",
    "            dep_T2H1 = build_T2H(dep1)   # 构建发射字典\n",
    "            so_spans1 = self.get_so(seg1, pos1, dep1, dep_T2H1)\n",
    "            if so_spans1 and so_spans1[0][1]-so_spans1[0][0]==preda[0]-i-3:\n",
    "                so = [i+2, preda[0]-1, 'node']\n",
    "                f2=True\n",
    "            # 连词之前的词属于一个名词短语\n",
    "            txt = ''.join(seg[:i])\n",
    "            seg1, pos1, dep1 = self.get_spd(txt)\n",
    "            dep_T2H1 = build_T2H(dep1)   # 构建发射字典\n",
    "            so_spans1 = self.get_so(seg1, pos1, dep1, dep_T2H1)\n",
    "            if so_spans1 and so_spans1[-1][-1]==i: \n",
    "                pre_so = so_spans1[-1] + ['node']\n",
    "                f3=True\n",
    "        \n",
    "        if f1 and f2 and f3: return True, [pre_so], [so]\n",
    "        return False, [], []\n",
    "\n",
    "        # so = idx_uncon_so_span.get(preda[0]-1, [0]).copy()\n",
    "        # pre_so = idx_uncon_so_span.get(so[0]-1, [])\n",
    "        # f1 = preda[-1]==len(pos) or pos[preda[-1]]=='wp'        # 谓语在句子最后\n",
    "        # f2 = so[-1] and seg[so[0]-1] in '与和跟'                # 谓语的前一个词是节点短语且第一个词是连词\n",
    "        # f3 = len(pre_so)                                        # 节点短语前面还是一个节点短语\n",
    "        # if f1 and f2 and f3:\n",
    "        #     so[0] += 1\n",
    "        #     pre_so.append('node')\n",
    "        #     so.append('node')\n",
    "        #     return True, [pre_so], [so]\n",
    "        # return False, [], []\n",
    "\n",
    "\n",
    "    def get_single_trips(\n",
    "        self, seg, pos, dep, dep_T2H, hed_spans, idx_preda_span,\n",
    "        idx_so_span, idx_uncon_so_span\n",
    "    ):\n",
    "        '''\n",
    "        针对每一个中心谓语，提取其三元组及嵌套的结果\n",
    "        得到简单三元组，解决了宾语从句的表示问题\n",
    "        根据主谓宾关系得到三元组、二元组\n",
    "        '''\n",
    "        # seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        # dep_T2H = self.dep_T2H\n",
    "        # preda_spans = self.preda_spans\n",
    "        # idx_so_span = self.idx_so_span\n",
    "        \n",
    "        def get_head_anchor(s):\n",
    "            '''得到头节点的锚点'''\n",
    "            anchor = -1\n",
    "            if 'SBV' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['SBV'][0]\n",
    "            elif 'FOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['FOB'][0]\n",
    "            elif dep[s-1][2] == 'COO':\n",
    "                anchor = get_head_anchor(dep[s-1][1])\n",
    "            return anchor\n",
    "        \n",
    "        def get_tail_anchor(s):\n",
    "            '''\n",
    "            得到尾节点的锚点\n",
    "            有动宾结构和介宾结构两种可能\n",
    "            '''\n",
    "            anchor = -1\n",
    "            if 'VOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['VOB'][0]\n",
    "            elif pos[s-1]=='p':\n",
    "                anchor = dep_T2H[s].get('POB', [-1])[0]\n",
    "            elif s<len(pos) and pos[s]=='p' and dep[s][1]==s:\n",
    "                anchor = dep_T2H[s+1].get('POB', [-1])[0]\n",
    "            return anchor\n",
    "\n",
    "        def preda_of_clause(anchor):\n",
    "            '''判断当前词是否为从句的谓词'''\n",
    "            f1 = pos[anchor-1] in ['v','p']\n",
    "            f2 = False\n",
    "            for tag in ['SBV','FOB','VOB']:\n",
    "                if have_dep(anchor-1, tag, dep, dep_T2H):\n",
    "                    f2 = True\n",
    "                    break\n",
    "            return f1 and f2\n",
    "\n",
    "        def get_node(anchor):\n",
    "            '''\n",
    "            根据anchor得到节点范围\n",
    "            谓词有COO则直接拆分为多个阶段\n",
    "            非谓词有COO则将其范围内连续的COO合成一个\n",
    "            '''\n",
    "            if anchor == -1:\n",
    "                return [None]\n",
    "            elif preda_of_clause(anchor):\n",
    "                # 当前中心语是宾语从句的谓词，则返回三元组列表\n",
    "                # anchor_list = [anchor] + get_all_coo(anchor-1, dep_T2H)\n",
    "                # node_list = []\n",
    "                # node_list = [get_recur_trip(idx_preda_span[a]) for a in anchor_list]\n",
    "                # node_list = [node.append('tri') for node in node_list]\n",
    "                # for a in anchor_list:\n",
    "                    # node_list += get_recur_trip(idx_preda_span[a])\n",
    "                    \n",
    "                # 规范树解析出错，需要分级解析：本规范要预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求\n",
    "                # 不用再管并列，把从句当主句时自会处理并列：当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器\n",
    "                start = find_smallest(dep_T2H, anchor)\n",
    "                end = find_biggest(dep_T2H, anchor)\n",
    "                txt = ''.join(seg[start-1:end])\n",
    "                # print('403', start, txt)\n",
    "                node_list = self.get_full_trips(txt, start-1)\n",
    "                for n in node_list: n.append('tri')\n",
    "                # node = get_recur_trip(idx_preda_span[anchor])\n",
    "                # 有COO则返回多个trip列表，统一格式，都返回node的列表\n",
    "                # 谓词也学SO搞个idx到span的映射，处理并列的情况\n",
    "                # return node\n",
    "                return node_list\n",
    "            else:\n",
    "                # start = find_smallest(dep_T2H, anchor)\n",
    "                # node = Node(start, anchor)\n",
    "                # node = [start, anchor]\n",
    "                node = idx_so_span.get(anchor, None)\n",
    "                if node[-1]!='node': node.append('node')\n",
    "                return [node]\n",
    "\n",
    "        def get_recur_trip(preda):\n",
    "            '''\n",
    "            得到带有递归节点的三元组\n",
    "            anchor有COO：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "            从句有COO：建筑的防火应符合下列目标要求：保障人身生命和财产安全、人身健康；\n",
    "            '''\n",
    "            flag, head, tail = self.bi_subj(preda, seg, pos)\n",
    "\n",
    "            if not flag:\n",
    "                anchor = get_head_anchor(preda[0])\n",
    "                head = get_node(anchor)\n",
    "\n",
    "                for p in preda:                         # 存在补语加VOB的情况：我们应看完饭、吃完饭、做完饭\n",
    "                    anchor = get_tail_anchor(p)\n",
    "                    if anchor!=-1: break\n",
    "                tail = get_node(anchor)\n",
    "\n",
    "            # 有多个head或tail则做笛卡尔积\n",
    "            if preda[-1]!='node': preda.append('node')\n",
    "            trip_list = []\n",
    "            '''\n",
    "            如果head和tail是node则要解析其定语\n",
    "                有谓语则解析句子，没谓语则当作节点定语\n",
    "            针对preda解析其状语，句子以句号为分隔\n",
    "                有谓语则解析句子，没谓语则当节点状语\n",
    "            可以先不处理定语\n",
    "            基本节点的格式为：{\n",
    "                trip: [h, preda, t],\n",
    "                modi_h: [node, cell],\n",
    "                modi_t: [node, cell],\n",
    "                adv: [node, cell]\n",
    "            }\n",
    "            '''\n",
    "            adv_list = []\n",
    "            for adv_anchor in dep_T2H:\n",
    "                pass\n",
    "            for h in head:\n",
    "                for t in tail:\n",
    "                    trip_list.append([h,preda,t])\n",
    "            return trip_list\n",
    "\n",
    "\n",
    "        # def get_node(anchor):\n",
    "        #     '''\n",
    "        #     根据anchor得到节点范围\n",
    "        #     谓词有COO则直接拆分为多个阶段\n",
    "        #     非谓词有COO则将其范围内连续的COO合成一个\n",
    "        #     '''\n",
    "        #     if anchor == -1:\n",
    "        #         return None\n",
    "        #     elif preda_of_clause(anchor):\n",
    "        #         # 当前中心语是宾语从句的谓词，则返回三元组列表\n",
    "        #         anchor_list = [anchor] + get_all_coo(anchor-1, dep_T2H)\n",
    "        #         node_list = [get_recur_trip(idx_preda_span[a]) for a in anchor_list]\n",
    "        #         # node_list = [node.append('tri') for node in node_list]\n",
    "        #         for n in node_list: n.append('tri')\n",
    "        #         print('365', node_list)\n",
    "        #         node = get_recur_trip(idx_preda_span[anchor])\n",
    "        #         # 有COO则返回多个trip列表，统一格式，都返回node的列表\n",
    "        #         # 谓词也学SO搞个idx到span的映射，处理并列的情况\n",
    "        #         # return node\n",
    "        #         return node_list\n",
    "        #     else:\n",
    "        #         # start = find_smallest(dep_T2H, anchor)\n",
    "        #         # node = Node(start, anchor)\n",
    "        #         # node = [start, anchor]\n",
    "        #         node = idx_so_span.get(anchor, None)\n",
    "        #         if node[-1]!='node': node.append('node')\n",
    "        #         return node\n",
    "\n",
    "        # def get_recur_trip(preda):\n",
    "        #     '''\n",
    "        #     得到带有递归节点的三元组\n",
    "        #     anchor有COO：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "        #     从句有COO：建筑的防火应符合下列目标要求：保障人身生命和财产安全、人身健康；\n",
    "        #     '''\n",
    "        #     anchor = get_head_anchor(preda[0])\n",
    "        #     head = get_node(anchor)\n",
    "\n",
    "        #     for p in preda:                         # 存在补语加VOB的情况：我们应看完饭、吃完饭、做完饭\n",
    "        #         anchor = get_tail_anchor(p)\n",
    "        #         if anchor!=-1: break\n",
    "        #     tail = get_node(anchor)\n",
    "\n",
    "        #     # 有多个head或tail则做笛卡尔积\n",
    "        #     if preda[-1]!='node': preda.append('node')\n",
    "        #     return [head, preda, tail]\n",
    "\n",
    "        # def get_str(spans):\n",
    "        #     '''递归得到字符串'''\n",
    "        #     spans_str = []\n",
    "        #     for s in spans:\n",
    "        #         # print('414', s)\n",
    "        #         # if len(s)==3:\n",
    "        #         if s[-1]!='node':\n",
    "        #             span_str = get_str(s)\n",
    "        #         else:\n",
    "        #             span_str = seg[s[0]-1:s[1]] if s else []\n",
    "        #         spans_str.append(span_str)\n",
    "        #     return spans_str\n",
    "\n",
    "        trip_spans = []\n",
    "        print('510', hed_spans)\n",
    "        for preda in hed_spans:\n",
    "            '''\n",
    "            根据谓词判断三元组，借助COO处理省略主语的情况\n",
    "            头实体：先找SBV、FOB，没有则顺着COO找，没有则用上级条文的主语\n",
    "            尾实体：找VOB，没有则记占位节点\n",
    "            仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定\n",
    "            连词相连的谓词要先合并再拆解\n",
    "            仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "            如果anchor处是从句的谓语，则递归执行该函数\n",
    "            '''\n",
    "            trip_spans += get_recur_trip(preda)\n",
    "        \n",
    "        '''在这里给'''\n",
    "        print(trip_spans)\n",
    "\n",
    "        def get_str(spans):\n",
    "            '''递归得到字符串'''\n",
    "            spans_str = []\n",
    "            for s in spans:\n",
    "                # print('414', s)\n",
    "                # if len(s)==3:\n",
    "                if not s:\n",
    "                    span_str = []\n",
    "                elif s[-1]=='tri':\n",
    "                    span_str = get_str(s[:-1])\n",
    "                elif s[-1]!='node':\n",
    "                    span_str = get_str(s)\n",
    "                else:\n",
    "                    span_str = seg[s[0]-1:s[1]]\n",
    "                spans_str.append(span_str)\n",
    "            return spans_str\n",
    "        \n",
    "        phrases = [\n",
    "            get_str(trip_span) for trip_span in trip_spans\n",
    "        ]\n",
    "        print('single trip phrases', phrases)\n",
    "        print(trip_spans)\n",
    "        return trip_spans\n",
    "\n",
    "    \n",
    "    def deal_digestion(self):\n",
    "        '''\n",
    "        确定其的指代内容\n",
    "        做三元组成分，则替换为对应的名词短语\n",
    "        做修饰语，则替换为名词短语+的\n",
    "        指代判定依据：前一个名词短语或三元组的头\n",
    "            所有最基本的头尾节点都要经过指代消解\n",
    "        做修饰语：陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；\n",
    "        做三元组成分：建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能；\n",
    "        远距离指代：设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道\n",
    "        '''\n",
    "        \n",
    "    def deal_attribute():\n",
    "        '''\n",
    "        处理开头是介词的，之间、间距、距离\n",
    "        短语开头是介词：消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。\n",
    "        短语结尾是之间、间距、距离：甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及与其他建筑的间距，应符合消防安全要求；\n",
    "        短语开头是介词，结尾是间距：易燃易爆危险品库房与在建工程的防火间距不应小于15m，与固定动作作业区不应小于12m，与邻近人员密集区、建筑物相对集中区及其他建筑的间距应符合消防要求；\n",
    "        省略属性，属性值的头实体应该是属性\n",
    "        '''\n",
    "\n",
    "    def split_phrase():\n",
    "        '''\n",
    "        分割名词短语\n",
    "        把部位当作属性节点\n",
    "        先把逗号分开，再按照一般拆解过程来\n",
    "        '''\n",
    "\n",
    "    def get_modi():\n",
    "        '''\n",
    "        定语从句，谓词是ATT的尾，向前向后找全覆盖\n",
    "        中心语用连续ATT和ADV确定范围\n",
    "        面积大于100平米的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。\n",
    "        实体的定语还是在关系节点上，内边上不附着定语或状语\n",
    "        '''\n",
    "    \n",
    "    def get_adv_trip():\n",
    "        '''解析状语从句'''\n",
    "    \n",
    "    def get_modi_trip():\n",
    "        '''解析定语从句'''\n",
    "\n",
    "'''\n",
    "把“压强”换成“压力”，解析完后再换回来\n",
    "词典缺失词替换\n",
    "提取带定语的名词短语\n",
    "提取谓词、状语\n",
    "提取三元组，状语内的名词短语不参与三元组构建\n",
    "嵌套提取主语从句、宾语从句中的三元组\n",
    "\n",
    "名词短语处理：\n",
    "共指消解，其\n",
    "处理双头属性，开头是介词的，之间、间距、距离\n",
    "\n",
    "名词短语解析，提取定语，定语分配给各个并列中心语\n",
    "定语分为修饰、从句、实体\n",
    "解析定语从句\n",
    "中心语分类，哪些是实体，哪些是属性\n",
    "解析一般实体，实体-包含-实体\n",
    "解析一般属性，实体-内边-属性\n",
    "处理省略实体、省略属性的属性，属性值之前必是属性\n",
    "拆解并列中心语\n",
    "'''\n",
    "\n",
    "rule_ner = RuleNER(ltp)\n",
    "txt = '建筑的选址和总平面布局应符合减小火灾危害，方便灭火救援的要求，并应符合下列规定'\n",
    "# txt = '生产和储存易燃易爆物品的工厂、仓库等应位于城镇规划区的边缘或相对独立的安全地带；'\n",
    "# txt = '储罐区的低倍数泡沫灭火系统应符合下列规定：对于非水溶性甲、乙、丙类液体固定顶储罐，应为液上喷射、液下喷射或半液下喷射系统；'\n",
    "txt = '甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及和其他建筑的间距，应符合消防安全要求；'\n",
    "# txt = '消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。'\n",
    "'''如果开头词性是p，则有可能表示属性，实体末尾是之间、距离，则要当相对属性来处理'''\n",
    "txt = '陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；'\n",
    "txt = '建筑内的防火分隔应能在其设计耐火时间内阻止火势与烟气蔓延至其他区域'\n",
    "txt = '设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道；'\n",
    "# txt = '除粮食等筒仓外，无法设置泄压设施或泄压面积不符合要求时，相应部位的建筑承重结构和防火分隔结构应满足抗爆要求。'\n",
    "'''有没有介词会很影响状语的抽取规则'''\n",
    "txt = '当仓库足够大时，仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定：'\n",
    "txt = '仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定'\n",
    "# txt = '仓库不应设在居住区内部'\n",
    "txt = '保障施工现场消防供水的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。'\n",
    "# txt = '戊类仓库的防火要求'\n",
    "# txt = '建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能'\n",
    "txt = '甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站'\n",
    "txt = '当温度大于或明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器'\n",
    "# txt = '温度大于30，湿度大于50'\n",
    "# txt = '当温度大于30或高度明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器'\n",
    "# txt = '建筑的防火应符合下列目标要求：保障生命财产安全和身体健康；'\n",
    "txt = '当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器'\n",
    "# txt = '仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定'\n",
    "# txt = '为了预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求，依据有关法律、法规，制定本规范。'\n",
    "# txt = '新建、改建和扩建建筑在规划、设计、施工与使用中的防火技术与措施，应遵守本规范。' # 有两个SBV\n",
    "txt = '当建筑防火中采用的方法、技术、材料与制品、措施等与本规范的规定不同或有特殊要求时，应根据本规范第2.1节进行合规性判定。'\n",
    "txt = '当方法与制品等与规定不同或有特殊要求时，应根据本规范第2.1节进行合规性判定。'\n",
    "# txt = '建筑防火中采用的方法、技术、材料与制品、措施等与本规范的规定不同或有特殊要求'\n",
    "# txt = '无障碍设施应保证安全和各类人群的方便使用。'\n",
    "# txt = '本规范适用于新建、扩建、改建的民用与工业建筑中自动喷水灭火系统的设计。'\n",
    "# txt = '本规范要预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求'\n",
    "# txt = '建筑中散发较空气重的可燃气体、蒸气或有粉尘、纤维爆炸危险的场所或部位应符合下列规定'\n",
    "# txt = '瓶装液化石油气不应与其他化学危险物品混放；'\n",
    "# txt = '生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触'\n",
    "# txt = '新建、改建或拆除建筑、结构、设备或类似活动所用临时电气线路和照明器具、涉及施工所需的易燃和可燃物质的使用与存放以及施工现场的用火、用电、用气应符合消防安全要求。'\n",
    "# txt = '地下、半地下场所内不应使用或储存液化石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道。'\n",
    "# txt = '地下、半地下场所内不应使用或储存液化石油气、可燃气体、液体燃料，不应有燃气或可燃液体配送管道。'\n",
    "# txt = '相对密度不小于0.75的可燃气体'\n",
    "txt = '施工临时办公与生活用房、发电机房、变配电站、厨房操作间、锅炉房和可燃材料与易燃易爆物品库房，当采用金属夹芯板材时，其芯材的燃烧性能应为A级。'\n",
    "res = rule_ner.get_spd(txt)\n",
    "word_pos = list(zip(res[0], res[1], res[2]))\n",
    "print(word_pos)\n",
    "# print(res[2])\n",
    "rule_ner.get_full_trips(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把模型分词错误的地方替换为可以正确分词的内容\n",
    "replace_dic = {'压强': '压力'}\n",
    "\n",
    "ltp.add_words(words=list(replace_dic.keys()), freq=2)\n",
    "\n",
    "def deal_miss_word(txt, replace_dic):\n",
    "    words = ltp.pipeline([txt], tasks = [\"cws\"]).cws[0]\n",
    "    recover_dic = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in replace_dic:\n",
    "            recover_dic[i] = words[i]\n",
    "            words[i] = replace_dic[words[i]]\n",
    "    return ''.join(words), recover_dic\n",
    "\n",
    "def span_contain(span1, span2):\n",
    "    '''span1是否包含span2'''\n",
    "    if span1[0]<=span2[0] and span1[1]>=span2[1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def del_intra_span(phrase_span):\n",
    "    '''去掉被其他span包围的span'''\n",
    "    merge_span = [phrase_span[-1]]\n",
    "    for i in range(len(phrase_span)-2, -1, -1):\n",
    "        cur_span = phrase_span[i]\n",
    "        if not span_contain(merge_span[-1], cur_span):\n",
    "        # if (cur_span[0]-merge_span[-1][0])*(merge_span[-1][1]-cur_span[1])<0:\n",
    "            merge_span.append(cur_span)\n",
    "    merge_span.reverse()\n",
    "    return merge_span\n",
    "\n",
    "def del_inter_span(lst1, lst2):\n",
    "    '''只保留span1中没有被span2中元素完全覆盖的部分'''\n",
    "    i, j = 0, 0\n",
    "    len1, len2 = len(lst1), len(lst2)\n",
    "    del_idx = []\n",
    "    while i<len1 and j<len2:\n",
    "        if span_contain(lst2[j], lst1[i]):\n",
    "            del_idx.append(i)\n",
    "            i += 1\n",
    "            continue\n",
    "        # if lst1[i][1]<=lst2[j][0]: i+=1\n",
    "        if lst2[j][1]<=lst1[i][0]: j += 1\n",
    "        else: i += 1\n",
    "    lst = [lst1[i] for i in range(len1) if i not in del_idx]\n",
    "    return lst\n",
    "\n",
    "# def deal_bi_\n",
    "\n",
    "'''\n",
    "node-edge-node\n",
    "node-edge-tri\n",
    "tri-edge-tri\n",
    "'''\n",
    "class Trip:\n",
    "    def __init__(self, head, edge, tail):\n",
    "        '''\n",
    "        mode: 元素的表达形式\n",
    "            span表示起止范围，如[2,5]；\n",
    "            str表示字符串，如'灭火器'\n",
    "        '''\n",
    "        self.head = head\n",
    "        self.edge = edge\n",
    "        self.tail = tail\n",
    "        self.val = '[{}-{}-{}]'.format(\n",
    "            head[1], edge[1], tail[1]\n",
    "        )\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "class RuleNER:\n",
    "    '''\n",
    "    用规则系统做NER\n",
    "    基本上所有以名词为中心语的短语都可以当作实体先抽出来\n",
    "    '''\n",
    "    def __init__(self, ltp) -> None:\n",
    "        self.ltp = ltp\n",
    "    \n",
    "    def get_spd(self, txt):\n",
    "        txt, recover_dic = deal_miss_word(txt, replace_dic)\n",
    "        result = self.ltp.pipeline([txt], tasks = [\"cws\",\"dep\",\"pos\"])\n",
    "        seg = result.cws[0]\n",
    "        pos = result.pos[0]\n",
    "        dep = result.dep[0]\n",
    "        for key in recover_dic:\n",
    "            seg[key] = recover_dic[key]\n",
    "        dep = list(zip(range(1,1+len(seg)), dep['head'], dep['label']))\n",
    "        return seg, pos, dep\n",
    "\n",
    "    def get_full_trips(self, txt):\n",
    "        '''得到扩展三元组'''\n",
    "        seg, pos, dep = self.get_spd(txt)\n",
    "        self.seg, self.pos, self.dep = seg, pos, dep\n",
    "        self.dep_T2H = build_T2H(dep)   # 构建发射字典\n",
    "        print('71 self.dep_T2H', self.dep_T2H)\n",
    "        self.noun_spans = self.get_noun()\n",
    "        self.adv_spans = self.get_adv()\n",
    "        self.preda_spans = self.get_preda()\n",
    "        self.get_single_trips()\n",
    "\n",
    "    def get_noun(self):\n",
    "        '''抽取以名词为中心语的短语'''\n",
    "        seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        phrase_span = []\n",
    "        for i in range(len(pos)):\n",
    "            # 状语，设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道；\n",
    "            if dep[i][2]=='ADV': continue\n",
    "            # 不是方位名词时基本是条件状语，不适合以此为中心语提取短语\n",
    "            if dep[i][2]=='POB' and pos[i]!='nd': continue\n",
    "            if 'n' in pos[i] or dep[i][2] in ['SBV','FOB','VOB']:\n",
    "                start = find_smallest(self.dep_T2H, i+1)\n",
    "                phrase_span.append([start, i+1])\n",
    "        if not len(phrase_span): return phrase_span\n",
    "        merge_span = del_intra_span(phrase_span)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        print('noun phrases', phrases)\n",
    "        return merge_span\n",
    "    \n",
    "    def get_adv(self):\n",
    "        '''\n",
    "        抽取状语\n",
    "        状中结构，从中心语向前找\n",
    "        介宾结构，从介词向后找\n",
    "        '''\n",
    "        seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        phrase_span = []\n",
    "        for i in range(len(pos)):\n",
    "            if dep[i][2]=='ADV':\n",
    "                # 状中结构ADV确定状语结束位置\n",
    "                start = find_smallest(self.dep_T2H, i+1)\n",
    "                phrase_span.append([start, i+1])\n",
    "            elif dep[i][2]=='POB':\n",
    "                # 介宾短语POB确定状语的结束位置\n",
    "                phrase_span.append([dep[i][1], i+1])\n",
    "        if not len(phrase_span): return phrase_span\n",
    "        merge_span = del_intra_span(phrase_span)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        print('adv phrases', phrases)\n",
    "        return merge_span\n",
    "\n",
    "    def get_preda(self, preda_list=[]):\n",
    "        '''\n",
    "        抽取谓词，没有处理主语从句、定语从句的谓词\n",
    "        句子的核心词及其并列词，且是动词或介词\n",
    "        是动词时需要将补语算作谓词的一部分\n",
    "        介词做谓语：仓库应在居住区外部\n",
    "        补语结构：仓库应设在居住区外部\n",
    "        '''\n",
    "        # 0: {'HED': [20]}\n",
    "        def coo_preda(i, pre_span):\n",
    "            '''\n",
    "            谓词并列需要满足三个条件\n",
    "            前一个词是表示并列的\n",
    "            跟上个span的第一个词是COO\n",
    "            跟上个span的最后一个词只隔一个词\n",
    "            样例：仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "            '''\n",
    "            f1 = seg[i-2]=='、' or dep_T2H[i].get('LAD', [-2])[0]==i-1\n",
    "            f2 = dep[i-1][1]==pre_span[0]\n",
    "            f3 = i - pre_span[-1]==2\n",
    "            return i>1 and f1 and f2 and f3\n",
    "\n",
    "        seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        dep_T2H = self.dep_T2H\n",
    "        phrase_span = []\n",
    "        head = dep_T2H[0]['HED'][0]\n",
    "        if not preda_list:\n",
    "            preda_list = [head] + dep_T2H.get(head,{}).get('COO',[])\n",
    "        for i in preda_list:\n",
    "            if pos[i-1] in ['v','p']:\n",
    "                start = i\n",
    "                # 动词带有补语其表意才完整：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "                end = dep_T2H.get(i, {}).get('CMP', [i])[0]\n",
    "                # print(seg[i-1], dep[i-1][2])\n",
    "                if dep[i-1][2]=='COO' and coo_preda(i, phrase_span[-1]):\n",
    "                    start = phrase_span[-1][0]\n",
    "                    phrase_span.pop()\n",
    "                phrase_span.append([start, end])\n",
    "\n",
    "        if not len(phrase_span): return phrase_span\n",
    "        merge_span = phrase_span\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        print('preda phrases', phrases)\n",
    "        return merge_span\n",
    "\n",
    "    # def get_\n",
    "\n",
    "    def get_single_trips(self):\n",
    "        '''\n",
    "        针对每一个中心谓语，提取其三元组及嵌套的结果\n",
    "        得到简单三元组，解决了宾语从句的表示问题\n",
    "        根据主谓宾关系得到三元组、二元组\n",
    "        '''\n",
    "        seg, pos, dep = self.seg, self.pos, self.dep\n",
    "        dep_T2H = self.dep_T2H\n",
    "        preda_spans = self.preda_spans\n",
    "        \n",
    "        def get_head_anchor(s):\n",
    "            '''得到头节点的锚点'''\n",
    "            anchor = -1\n",
    "            if 'SBV' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['SBV'][0]\n",
    "            elif 'FOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['FOB'][0]\n",
    "            elif dep[s-1][2] == 'COO':\n",
    "                anchor = get_head_anchor(dep[s-1][1])\n",
    "            return anchor\n",
    "        \n",
    "        def get_tail_anchor(s):\n",
    "            '''\n",
    "            得到尾节点的锚点\n",
    "            有动宾结构和介宾结构两种可能\n",
    "            '''\n",
    "            anchor = -1\n",
    "            if 'VOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['VOB'][0]\n",
    "            elif pos[s-1]=='p':\n",
    "                anchor = dep_T2H[s].get('POB', [-1])[0]\n",
    "            elif s<len(pos) and pos[s]=='p' and dep[s][1]==s:\n",
    "                anchor = dep_T2H[s+1].get('POB', [-1])[0]\n",
    "            return anchor\n",
    "\n",
    "        def preda_of_clause(anchor):\n",
    "            '''判断当前词是否为从句的谓词'''\n",
    "            f1 = pos[anchor-1] in ['v','p']\n",
    "            f2 = False\n",
    "            for syn in ['SBV','FOB','VOB']:\n",
    "                if syn in dep_T2H[anchor]:\n",
    "                    f2 = True\n",
    "                    break\n",
    "            return f1 and f2\n",
    "\n",
    "        def get_node(anchor):\n",
    "            '''\n",
    "            根据anchor得到节点范围\n",
    "            谓词有COO则直接拆分为多个阶段\n",
    "            非谓词有COO则将其范围内连续的COO合成一个\n",
    "            '''\n",
    "            if anchor == -1:\n",
    "                node = None\n",
    "            elif preda_of_clause(anchor):\n",
    "                # 当前中心语是宾语从句的谓词，则返回三元组列表\n",
    "                node = get_recur_trip([anchor, anchor])\n",
    "                # 有COO则返回多个trip列表，统一格式，都返回node的列表\n",
    "            else:\n",
    "                start = find_smallest(dep_T2H, anchor)\n",
    "                node = [start, anchor]\n",
    "            return node\n",
    "\n",
    "        def get_recur_trip(preda):\n",
    "            '''\n",
    "            得到带有递归节点的三元组\n",
    "            anchor有COO：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "            从句有COO：建筑的防火应符合下列目标要求：保障人身生命和财产安全、人身健康；\n",
    "            '''\n",
    "            anchor = get_head_anchor(preda[0])\n",
    "            head = get_node(anchor)\n",
    "\n",
    "            anchor = get_tail_anchor(preda[0])\n",
    "            tail = get_node(anchor)\n",
    "\n",
    "            # 有多个head或tail则做笛卡尔积\n",
    "            \n",
    "            return [head, preda, tail]\n",
    "\n",
    "        trip_spans = []\n",
    "        for preda in preda_spans:\n",
    "            '''\n",
    "            根据谓词判断三元组，借助COO处理省略主语的情况\n",
    "            头实体：先找SBV、FOB，没有则顺着COO找，没有则用上级条文的主语\n",
    "            尾实体：找VOB，没有则记占位节点\n",
    "            仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定\n",
    "            连词相连的谓词要先合并再拆解\n",
    "            仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "            如果anchor处是从句的谓语，则递归执行该函数\n",
    "            '''\n",
    "            trip_spans.append(get_recur_trip(preda))\n",
    "        \n",
    "        def get_str(spans):\n",
    "            '''递归得到字符串'''\n",
    "            spans_str = []\n",
    "            for s in spans:\n",
    "                if len(s)==3:\n",
    "                    span_str = get_str(s)\n",
    "                else:\n",
    "                    span_str = seg[s[0]-1:s[1]] if s else []\n",
    "                spans_str.append(span_str)\n",
    "            return spans_str\n",
    "        \n",
    "        phrases = [\n",
    "            get_str(trip_span) for trip_span in trip_spans\n",
    "        ]\n",
    "        print('single trip phrases', phrases)\n",
    "        print(trip_spans)\n",
    "        return trip_spans\n",
    "\n",
    "    \n",
    "    def deal_digestion(self):\n",
    "        '''\n",
    "        确定其的指代内容\n",
    "        做三元组成分，则替换为对应的名词短语\n",
    "        做修饰语，则替换为名词短语+的\n",
    "        指代判定依据：前一个名词短语或三元组的头\n",
    "            所有最基本的头尾节点都要经过指代消解\n",
    "        做修饰语：陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；\n",
    "        做三元组成分：建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能；\n",
    "        远距离指代：设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道\n",
    "        '''\n",
    "        \n",
    "    def deal_attribute():\n",
    "        '''\n",
    "        处理开头是介词的，之间、间距、距离\n",
    "        短语开头是介词：消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。\n",
    "        短语结尾是之间、间距、距离：甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及与其他建筑的间距，应符合消防安全要求；\n",
    "        短语开头是介词，结尾是间距：易燃易爆危险品库房与在建工程的防火间距不应小于15m，与固定动作作业区不应小于12m，与邻近人员密集区、建筑物相对集中区及其他建筑的间距应符合消防要求；\n",
    "        省略属性，属性值的头实体应该是属性\n",
    "        '''\n",
    "\n",
    "    def split_phrase():\n",
    "        '''\n",
    "        分割名词短语\n",
    "        把部位当作属性节点\n",
    "        先把逗号分开，再按照一般拆解过程来\n",
    "        '''\n",
    "\n",
    "    def get_modi():\n",
    "        '''\n",
    "        定语从句，谓词是ATT的尾，向前向后找全覆盖\n",
    "        中心语用连续ATT和ADV确定范围\n",
    "        面积大于100平米的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。\n",
    "        '''\n",
    "\n",
    "'''\n",
    "把“压强”换成“压力”，解析完后再换回来\n",
    "词典缺失词替换\n",
    "提取带定语的名词短语\n",
    "提取谓词、状语\n",
    "提取三元组，状语内的名词短语不参与三元组构建\n",
    "嵌套提取主语从句、宾语从句中的三元组\n",
    "\n",
    "名词短语处理：\n",
    "共指消解，其\n",
    "处理双头属性，开头是介词的，之间、间距、距离\n",
    "\n",
    "名词短语解析，提取定语，定语分配给各个并列中心语\n",
    "定语分为修饰、从句、实体\n",
    "解析定语从句\n",
    "中心语分类，哪些是实体，哪些是属性\n",
    "解析一般实体，实体-包含-实体\n",
    "解析一般属性，实体-内边-属性\n",
    "处理省略实体、省略属性的属性，属性值之前必是属性\n",
    "拆解并列中心语\n",
    "'''\n",
    "\n",
    "rule_ner = RuleNER(ltp)\n",
    "txt = '建筑的选址和总平面布局应符合减小火灾危害，方便灭火救援的要求，并应符合下列规定'\n",
    "# txt = '生产和储存易燃易爆物品的工厂、仓库等应位于城镇规划区的边缘或相对独立的安全地带；'\n",
    "# txt = '储罐区的低倍数泡沫灭火系统应符合下列规定：对于非水溶性甲、乙、丙类液体固定顶储罐，应为液上喷射、液下喷射或半液下喷射系统；'\n",
    "txt = '甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及和其他建筑的间距，应符合消防安全要求；'\n",
    "# txt = '消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。'\n",
    "'''如果开头词性是p，则有可能表示属性，实体末尾是之间、距离，则要当相对属性来处理'''\n",
    "txt = '陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；'\n",
    "txt = '建筑内的防火分隔应能在其设计耐火时间内阻止火势与烟气蔓延至其他区域'\n",
    "txt = '设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道；'\n",
    "# txt = '除粮食等筒仓外，无法设置泄压设施或泄压面积不符合要求时，相应部位的建筑承重结构和防火分隔结构应满足抗爆要求。'\n",
    "'''有没有介词会很影响状语的抽取规则'''\n",
    "txt = '当仓库足够大时，仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定：'\n",
    "txt = '仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定'\n",
    "# txt = '仓库不应设在居住区内部'\n",
    "txt = '保障施工现场消防供水的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。'\n",
    "# txt = '戊类仓库的防火要求'\n",
    "# txt = '建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能'\n",
    "txt = '甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站'\n",
    "res = rule_ner.get_spd(txt)\n",
    "word_pos = list(zip(res[0], res[1], res[2]))\n",
    "# print(word_pos)\n",
    "# print(res[2])\n",
    "rule_ner.get_full_trips(txt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc293f25d9b2e08ed2fd720b85589440a3807ec86f7cee2822a6b1ce149b10db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
