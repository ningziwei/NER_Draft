{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_T2H(dep):\n",
    "    '''\n",
    "    根据依存树构建每个词的发射字典\n",
    "    txt: 设备机房、电梯机房、水箱间、天线\n",
    "    dep: [\n",
    "        (1, 2, 'ATT'), (2, 0, 'HED'), (3, 5, 'WP'), \n",
    "        (4, 5, 'ATT'), (5, 2, 'COO'), (6, 7, 'WP'), \n",
    "        (7, 2, 'COO'), (8, 9, 'WP'), (9, 2, 'COO')\n",
    "    ]\n",
    "    return {\n",
    "        2: {'ATT': [1], 'COO': [5, 7, 9]}, \n",
    "        0: {'HED': [2]}, \n",
    "        5: {'ATT': [4]}\n",
    "    }\n",
    "    '''\n",
    "    dep_T2H = defaultdict(dict)\n",
    "    for d in dep:\n",
    "        # if d[2] in ['WP','LAD']: continue\n",
    "        if d[1] in dep_T2H:\n",
    "            dep_T2H[d[1]][d[2]] = dep_T2H[d[1]].get(d[2],[])+[d[0]]\n",
    "        else:\n",
    "            dep_T2H[d[1]] = {d[2]:[d[0]]}\n",
    "    return dep_T2H\n",
    "    \n",
    "def find_smallest(dep_T2H, p):\n",
    "    '''\n",
    "    寻找当前中心语的覆盖的围\n",
    "    由于不存在交叉的情况，所以只要往前找最小的即可\n",
    "    return: 第一个词对应的位置\n",
    "    '''\n",
    "    if p==0: return 1\n",
    "    p_out = list(dep_T2H.get(p,{}).values())\n",
    "    p_out = list(chain(*p_out))\n",
    "    if not p_out or min(p_out)>p: return p\n",
    "    smallest = find_smallest(dep_T2H, min(p_out))\n",
    "    return smallest\n",
    "\n",
    "def find_biggest(dep_T2H, p):\n",
    "    '''\n",
    "    寻找当前中心语的覆盖范围\n",
    "    由于不存在交叉的情况，所以只要往后找最大的即可\n",
    "    return: 最后一个词对应的位置\n",
    "    '''\n",
    "    p_out = list(dep_T2H.get(p,{}).values())\n",
    "    p_out = list(chain(*p_out))\n",
    "    if not p_out or max(p_out)<p: return p\n",
    "    biggest = find_biggest(dep_T2H, max(p_out))\n",
    "    return biggest\n",
    "\n",
    "ltp = LTP('LTP/small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'给水厂应对制水生产中的主要设施、设备制定和实施巡查维护保养制度，应对主要工艺运行情况及其运行中的动态技术参数，制定和实施质量控制点检验制度'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 危险做名词成分时替换为危险性\n",
    "'建筑无法设置泄压设施或泄压面积不符合要求时，建筑中存在可燃气体或纤维爆炸危险性的部位的建筑承重结构应满足抗爆要求。'\n",
    "'地面特殊设施基地或地下特殊设施的地面附属设施，距易发生危险的建筑物、仓库、储罐、可燃物品和材料堆场等，应满足安全防护距离的要求。'\n",
    "# “及其”需要特殊处理\n",
    "'给水厂应对制水生产中的主要设施、设备制定和实施巡查维护保养制度，应对主要工艺运行情况及其运行中的动态技术参数，制定和实施质量控制点检验制度'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 添加表述规范化模块 #########\n",
    "'''\n",
    "识别出来符合，替换为同义词满足\n",
    "城乡给水工程建设规模的划分应符合表2.0.23的要求\n",
    "标准定语是带“的”的，实体连续修饰实体需要拆分，中心语要是简单概念\n",
    "标准贯入试验设备应符合表 5.0.4 的规定。\n",
    ", '符合表': '满足表'\n",
    "\n",
    "绿道连接线不应直接借道国道、省道等干线公路及快速路等道路；\n",
    "'''\n",
    "# 把模型分词错误的地方替换为可以正确分词的内容\n",
    "replace_dic = {'压强':'压力', '借道':'取道'}\n",
    "\n",
    "ltp.add_words(words=list(replace_dic.keys()), freq=2)\n",
    "\n",
    "def deal_miss_word(txt, replace_dic):\n",
    "    '''\n",
    "    未登录词加入词典后虽然可以获得正确的分词结果，但句法分析依然有错误\n",
    "    所以需要将对应词替换为本来就可以正确分词的内容\n",
    "    例：泄压部位应能在爆炸作用达到结构最大耐受压强前泄压；\n",
    "    '''\n",
    "    words = ltp.pipeline([txt], tasks = [\"cws\"]).cws[0]\n",
    "    # print('@@@@', words)\n",
    "    recover_dic = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in replace_dic:\n",
    "            recover_dic[i] = words[i]\n",
    "            words[i] = replace_dic[words[i]]\n",
    "    return ''.join(words), recover_dic\n",
    "\n",
    "def span_contain(span1, span2):\n",
    "    '''span1是否包含span2'''\n",
    "    if span1[0]<=span2[0] and span1[1]>=span2[1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def del_intra_span(phrase_span):\n",
    "    '''去掉被其他span包围的span'''\n",
    "    if not phrase_span: return phrase_span\n",
    "    merge_span = [phrase_span[-1]]\n",
    "    for i in range(len(phrase_span)-2, -1, -1):\n",
    "        cur_span = phrase_span[i]\n",
    "        if not span_contain(merge_span[-1], cur_span):\n",
    "        # if (cur_span[0]-merge_span[-1][0])*(merge_span[-1][1]-cur_span[1])<0:\n",
    "            merge_span.append(cur_span)\n",
    "    merge_span.reverse()\n",
    "    return merge_span\n",
    "\n",
    "def del_inter_span(lst1, lst2):\n",
    "    '''只保留span1中没有被span2中元素完全覆盖的部分'''\n",
    "    i, j = 0, 0\n",
    "    len1, len2 = len(lst1), len(lst2)\n",
    "    del_idx = []\n",
    "    while i<len1 and j<len2:\n",
    "        if span_contain(lst2[j], lst1[i]):\n",
    "            del_idx.append(i)\n",
    "            i += 1\n",
    "            continue\n",
    "        # if lst1[i][1]<=lst2[j][0]: i+=1\n",
    "        if lst2[j][1]<=lst1[i][0]: j += 1\n",
    "        else: i += 1\n",
    "    lst = [lst1[i] for i in range(len1) if i not in del_idx]\n",
    "    return lst\n",
    "\n",
    "\n",
    "'''\n",
    "node-edge-node\n",
    "node-edge-tri\n",
    "tri-edge-tri\n",
    "'''\n",
    "class Trip:\n",
    "    def __init__(self, head, rel, tail):\n",
    "        '''\n",
    "        mode: 元素的表达形式\n",
    "            span表示起止范围，如[2,5]；\n",
    "            str表示字符串，如'灭火器'\n",
    "        '''\n",
    "        self.head = head\n",
    "        self.rel = rel\n",
    "        self.tail = tail\n",
    "        # self.val = '[{}-{}-{}]'.format(\n",
    "        #     head[1], rel[1], tail[1]\n",
    "        # )\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "def have_dep(idx, tag, dep, dep_T2H):\n",
    "    '''判断当前词是否做对应成分'''\n",
    "    f1 = tag in dep_T2H[idx+1]\n",
    "    f2 = False\n",
    "    if dep[idx][2] == 'COO':\n",
    "        f2 = have_dep(dep[idx][1]-1, tag, dep, dep_T2H)\n",
    "    return f1 or f2\n",
    "\n",
    "def get_all_coo(idx, dep_T2H):\n",
    "    '''按照在序列中出现的顺序得到和当前词并列的所有词'''\n",
    "    c1 = dep_T2H[idx+1].get('COO', [])\n",
    "    c2 = []\n",
    "    for c in c1:\n",
    "        c2.append(c)\n",
    "        c2 += get_all_coo(c-1, dep_T2H)\n",
    "    return c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "seg = list('asdfs（）sda')\n",
    "seg.index('（')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "# %aimport KPR\n",
    "import KPR\n",
    "'''\n",
    "autoreload的意思是自动重新装入，它后面可带参数。\n",
    "无参：装入所有模块\n",
    "0：不执行装入命令。\n",
    "1：只装入所有%aimport 要装的模块。\n",
    "2：装入所有%aimport不包含的模块。'''\n",
    "\n",
    "\n",
    "class RuleNER:\n",
    "    '''\n",
    "    用规则系统做NER\n",
    "    基本上所有以名词为中心语的短语都可以当作实体先抽出来\n",
    "    '''\n",
    "    def __init__(self, ltp) -> None:\n",
    "        self.ltp = ltp\n",
    "    \n",
    "    def get_spd(self, txt):\n",
    "        txt, recover_dic = deal_miss_word(txt, replace_dic)\n",
    "        result = self.ltp.pipeline([txt], tasks = [\"cws\",\"dep\",\"pos\"])\n",
    "        seg = result.cws[0]\n",
    "        pos = result.pos[0]\n",
    "        dep = result.dep[0]\n",
    "        for key in recover_dic:\n",
    "            seg[key] = recover_dic[key]\n",
    "        dep = list(zip(range(1,1+len(seg)), dep['head'], dep['label']))\n",
    "        return seg, pos, dep\n",
    "\n",
    "    def test(self, txt):\n",
    "        '''测试所有函数'''\n",
    "        seg, pos, dep = self.get_spd(txt)\n",
    "        new_txt = self.del_brackets(seg, pos, dep)\n",
    "        print(new_txt)\n",
    "\n",
    "    def get_att_head_phrase(self, txt):\n",
    "        '''得到定中短语'''\n",
    "        seg, pos, dep = self.get_spd(txt)\n",
    "        dep_T2H = build_T2H(dep)   # 构建发射字典\n",
    "        phrase_span = KPR.get_so(seg, pos, dep, dep_T2H)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in phrase_span]\n",
    "        return phrases\n",
    "\n",
    "    def get_full_trips(self, txt, offset=0):\n",
    "        '''得到扩展三元组'''\n",
    "        seg, pos, dep = self.get_spd(txt)\n",
    "        dep_T2H = build_T2H(dep)   # 构建发射字典\n",
    "        print('71 self.dep_T2H', dep_T2H)\n",
    "        so_spans = KPR.get_so(seg, pos, dep, dep_T2H)\n",
    "        adv_spans = self.get_adv(seg, pos, dep, dep_T2H)\n",
    "        preda_spans = self.get_preda(seg, pos, dep, dep_T2H)\n",
    "\n",
    "        idx_so_span = {}\n",
    "        idx_uncon_so_span = {}\n",
    "        idx_preda_span = {}\n",
    "        for span in so_spans:\n",
    "            idx_so_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        # for span in uncon_so_spans:\n",
    "        #     idx_uncon_so_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        for span in preda_spans:\n",
    "            idx_preda_span.update({s:span for s in range(span[0], span[1]+1)})\n",
    "        head = list(dep_T2H[0].values())[0][0]\n",
    "        hed_list = [head] + get_all_coo(head-1, dep_T2H)\n",
    "        ########## 要处理解析结果中没有谓语的情况 ##########\n",
    "        # 相对密度不小于0.75的可燃气体\n",
    "        print('132', hed_list)\n",
    "        hed_spans = [idx_preda_span[i] for i in hed_list]\n",
    "        hed_spans = del_intra_span(hed_spans)\n",
    "        print('135', hed_list, hed_spans)\n",
    "        \n",
    "        single_trips = self.get_single_trips(\n",
    "            seg, pos, dep, dep_T2H, hed_spans, idx_preda_span, \n",
    "            idx_so_span, idx_uncon_so_span\n",
    "        )\n",
    "        \n",
    "        def shift_offset(spans):\n",
    "            '''递归得到字符串'''\n",
    "            spans_shift = []\n",
    "            for s in spans:\n",
    "                # print('414', s)\n",
    "                # if len(s)==3:\n",
    "                if not s:\n",
    "                    span_str = None\n",
    "                elif s[-1]=='tri':\n",
    "                    span_str = shift_offset(s[:-1])\n",
    "                    span_str.append('tri')\n",
    "                elif s[-1]!='node':\n",
    "                    span_str = shift_offset(s)\n",
    "                else:\n",
    "                    span_str = [s[0]+offset, s[1]+offset]\n",
    "                    span_str.append('node')\n",
    "                spans_shift.append(span_str)\n",
    "            return spans_shift\n",
    "        \n",
    "        single_trips = [\n",
    "            shift_offset(single_trip) for single_trip in single_trips\n",
    "        ]\n",
    "        # print('154', single_trips)\n",
    "        return single_trips\n",
    "\n",
    "    def get_att_head(self, seg, pos, dep, dep_T2H):\n",
    "        '''\n",
    "        提取以助词“的”结尾的定语：\n",
    "            从后往前找，碰到“的”则判断是否为定语\n",
    "            “的”不在短句最后，RAD的词的覆盖范围\n",
    "        去掉定语后的句子，定语在句子中的对应部分\n",
    "        给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "        '''\n",
    "        \n",
    "\n",
    "    def get_adv(self, seg, pos, dep, dep_T2H):\n",
    "        '''\n",
    "        抽取状语\n",
    "        状中结构，从中心语向前找\n",
    "        介宾结构，从介词向后找\n",
    "        '''\n",
    "        phrase_span = []\n",
    "        for i in range(len(pos)):\n",
    "            if dep[i][2]=='ADV':\n",
    "                # 状中结构ADV确定状语结束位置：当温度大于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "                start = find_smallest(dep_T2H, i+1)\n",
    "                end = dep_T2H[i+1].get('POB', [i+1])[0]\n",
    "                phrase_span.append([start, end])\n",
    "            elif dep[i][2]=='POB' and dep[dep[i][1]-1]=='ADV':\n",
    "                # 介宾短语POB确定状语的结束位置：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "                phrase_span.append([dep[i][1], i+1])\n",
    "        merge_span = del_intra_span(phrase_span)\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        print('adv phrases', phrases)\n",
    "        return merge_span\n",
    "\n",
    "    def get_preda(self, seg, pos, dep, dep_T2H):\n",
    "        '''\n",
    "        像SO一样抽取所有的谓词，在三元组抽取中，用HED及其并列位置借助字典进行映射\n",
    "        抽取谓词，没有处理主语从句、定语从句的谓词\n",
    "        句子的核心词及其并列词，且是动词或介词\n",
    "        是动词时需要将补语算作谓词的一部分\n",
    "        介词做谓语：仓库应在居住区外部\n",
    "        补语结构：仓库应设在居住区外部\n",
    "        '''\n",
    "        # 0: {'HED': [20]}\n",
    "        def is_concat_preda(i, pre_span):\n",
    "            '''\n",
    "            谓词合并需要满足三个条件\n",
    "            f1：连词直接连到上一个span后面\n",
    "            f2：当前谓词跟上一个span的谓词是并列关系\n",
    "            f3：当前谓词没有直接相连的FOB或SBV\n",
    "            样例：\n",
    "                仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "                当温度大于或明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器\n",
    "            '''\n",
    "            # f1 = seg[i-2]=='、' or dep_T2H[i].get('LAD', [-2])[0]==i-1\n",
    "            # print('245', i, dep[i-1], pre_span, dep[i-1][1]==pre_span[0])\n",
    "            # f1 = seg[i-2]=='、' or dep_T2H[i].get('LAD', [-2])[0]==pre_span[-1]+1\n",
    "            # f2 = dep[i-1][1]==pre_span[0]\n",
    "            # f3 = 'SBV' not in dep_T2H[i] and 'FOB' not in dep_T2H[i]\n",
    "            # return i>1 and f1 and f2 and f3\n",
    "            if not pre_span: return False\n",
    "            f1 = seg[i-1]=='、' or dep_T2H[i+1].get('LAD', [-2])[0]==pre_span[-1]+1\n",
    "            f1 = f1 or dep[i][0]-dep[i][1]==1                                           # 跟上一个动词连续并列：在建筑防火中贯彻执行国家技术经济政策\n",
    "            f2 = dep[i][1]==pre_span[0]\n",
    "            f3 = 'SBV' not in dep_T2H[i+1] and 'FOB' not in dep_T2H[i+1]\n",
    "            return i>0 and f1 and f2 and f3\n",
    "\n",
    "        phrase_span = [[]]\n",
    "        for i in range(len(pos)):\n",
    "            f1 = False\n",
    "            for tag in ['SBV','FOB','VOB']:\n",
    "                if have_dep(i, tag, dep, dep_T2H):\n",
    "                    f1 = True\n",
    "                    break\n",
    "            f2 = pos[i]!='a'\n",
    "            f3 = pos[i]=='a' and dep_T2H[i+1].get('SBV',[-1])[0]!=i\n",
    "            if f1 and (f2 or f3):\n",
    "                start = i + 1\n",
    "                # 动词带有补语其表意才完整：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "                end = dep_T2H.get(i+1).get('CMP', [i+1])[0]\n",
    "                if dep[i][2]=='COO' and is_concat_preda(i, phrase_span[-1]):\n",
    "                    start = phrase_span[-1][0]\n",
    "                    phrase_span.pop()\n",
    "                phrase_span.append([start, end])\n",
    "        phrase_span = phrase_span[1:]\n",
    "\n",
    "        # phrase_span = []\n",
    "        # head = dep_T2H[0]['HED'][0]\n",
    "        # # preda_list = [head] + dep_T2H.get(head,{}).get('COO',[])\n",
    "        # preda_list = [head] + get_all_coo(head-1, dep_T2H)\n",
    "        # for i in preda_list:\n",
    "        #     if pos[i-1] in ['v','p']:\n",
    "        #         start = i\n",
    "        #         # 动词带有补语其表意才完整：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "        #         end = dep_T2H.get(i, {}).get('CMP', [i])[0]\n",
    "        #         if dep[i-1][2]=='COO' and is_concat_preda(i, phrase_span[-1]):\n",
    "        #             start = phrase_span[-1][0]\n",
    "        #             phrase_span.pop()\n",
    "        #         phrase_span.append([start, end])\n",
    "\n",
    "        phrases = [seg[s[0]-1:s[1]] for s in phrase_span]\n",
    "        print('preda phrases', phrases)\n",
    "        # merge_span = del_intra_span(phrase_span)\n",
    "        # phrases = [seg[s[0]-1:s[1]] for s in merge_span]\n",
    "        # print('preda merge_span', phrases)\n",
    "        return phrase_span\n",
    "    \n",
    "    def bi_subj(self, preda, seg, pos):\n",
    "        '''\n",
    "        处理双主语结构的句子\n",
    "        看似没有宾语，但实际上是两个主语发生这个动作\n",
    "        也会出现在定语从句、主语从句中\n",
    "        满足判定条件则返回双主语构成的三元组\n",
    "            谓语在句子最后，且要对谓词分类，把谓词出现在句尾的拿出来，标一下分类数据\n",
    "            连词和谓语之间是一个完整的名词短语\n",
    "            连词之前的词属于一个名词短语\n",
    "        样例：\n",
    "        瓶装液化石油气不应跟其他化学危险物品混放；\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触能引起燃烧的场所\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触能引起燃烧\n",
    "        生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触    短语的合并需要打补丁\n",
    "        '''\n",
    "        ########## 需要根据谓词类别判断是双主语还是单主语 ##########\n",
    "        f1 = preda[-1]==len(pos) or pos[preda[-1]]=='wp'        # 谓语在句子最后\n",
    "        f2 = False\n",
    "        f3 = False\n",
    "        for i in range(preda[0]-1, -1, -1):\n",
    "            if seg[i] in '与和跟': break\n",
    "        if i>0:\n",
    "            # 连词和谓语之间是一个完整的名词短语\n",
    "            txt = ''.join(seg[i+1:preda[0]-1])\n",
    "            seg1, pos1, dep1 = self.get_spd(txt)\n",
    "            dep_T2H1 = build_T2H(dep1)   # 构建发射字典\n",
    "            so_spans1 = KPR.get_so(seg1, pos1, dep1, dep_T2H1)\n",
    "            if so_spans1 and so_spans1[0][1]-so_spans1[0][0]==preda[0]-i-3:\n",
    "                so = [i+2, preda[0]-1, 'node']\n",
    "                f2=True\n",
    "            # 连词之前的词属于一个名词短语\n",
    "            txt = ''.join(seg[:i])\n",
    "            seg1, pos1, dep1 = self.get_spd(txt)\n",
    "            dep_T2H1 = build_T2H(dep1)   # 构建发射字典\n",
    "            so_spans1 = KPR.get_so(seg1, pos1, dep1, dep_T2H1)\n",
    "            if so_spans1 and so_spans1[-1][-1]==i: \n",
    "                pre_so = so_spans1[-1] + ['node']\n",
    "                f3=True\n",
    "        \n",
    "        if f1 and f2 and f3: return True, [pre_so], [so]\n",
    "        return False, [], []\n",
    "\n",
    "    def get_single_trips(\n",
    "        self, seg, pos, dep, dep_T2H, hed_spans, idx_preda_span,\n",
    "        idx_so_span, idx_uncon_so_span\n",
    "    ):\n",
    "        '''\n",
    "        针对每一个中心谓语，提取其三元组及嵌套的结果\n",
    "        得到简单三元组，解决了宾语从句的表示问题\n",
    "        根据主谓宾关系得到三元组、二元组\n",
    "        '''\n",
    "        \n",
    "        def get_head_anchor(s):\n",
    "            '''得到头节点的锚点'''\n",
    "            anchor = -1\n",
    "            if 'SBV' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['SBV'][0]\n",
    "            elif 'FOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['FOB'][0]\n",
    "            elif dep[s-1][2] == 'COO':\n",
    "                anchor = get_head_anchor(dep[s-1][1])\n",
    "            return anchor\n",
    "        \n",
    "        def get_tail_anchor(s):\n",
    "            '''\n",
    "            得到尾节点的锚点\n",
    "            有动宾结构和介宾结构两种可能\n",
    "            '''\n",
    "            anchor = -1\n",
    "            if 'VOB' in dep_T2H[s]:\n",
    "                anchor = dep_T2H[s]['VOB'][0]\n",
    "            elif pos[s-1]=='p':\n",
    "                anchor = dep_T2H[s].get('POB', [-1])[0]\n",
    "            elif s<len(pos) and pos[s]=='p' and dep[s][1]==s:\n",
    "                anchor = dep_T2H[s+1].get('POB', [-1])[0]\n",
    "            return anchor\n",
    "\n",
    "        def preda_of_clause(anchor):\n",
    "            '''判断当前词是否为从句的谓词'''\n",
    "            f1 = pos[anchor-1] in ['v','p']\n",
    "            f2 = False\n",
    "            for tag in ['SBV','FOB','VOB']:\n",
    "                if have_dep(anchor-1, tag, dep, dep_T2H):\n",
    "                    f2 = True\n",
    "                    break\n",
    "            return f1 and f2\n",
    "\n",
    "        def get_node(anchor):\n",
    "            '''\n",
    "            根据anchor得到节点范围\n",
    "            谓词有COO则直接拆分为多个阶段\n",
    "            非谓词有COO则将其范围内连续的COO合成一个\n",
    "            '''\n",
    "            if anchor == -1:\n",
    "                return [None]\n",
    "            elif preda_of_clause(anchor):\n",
    "                # 当前中心语是宾语从句的谓词，则返回三元组列表\n",
    "                # anchor_list = [anchor] + get_all_coo(anchor-1, dep_T2H)\n",
    "                # node_list = []\n",
    "                # node_list = [get_recur_trip(idx_preda_span[a]) for a in anchor_list]\n",
    "                # node_list = [node.append('tri') for node in node_list]\n",
    "                # for a in anchor_list:\n",
    "                    # node_list += get_recur_trip(idx_preda_span[a])\n",
    "                    \n",
    "                # 规范树解析出错，需要分级解析：本规范要预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求\n",
    "                # 不用再管并列，把从句当主句时自会处理并列：当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器\n",
    "                start = find_smallest(dep_T2H, anchor)\n",
    "                end = find_biggest(dep_T2H, anchor)\n",
    "                txt = ''.join(seg[start-1:end])\n",
    "                # print('403', start, txt)\n",
    "                node_list = self.get_full_trips(txt, start-1)\n",
    "                for n in node_list: n.append('tri')\n",
    "                # node = get_recur_trip(idx_preda_span[anchor])\n",
    "                # 有COO则返回多个trip列表，统一格式，都返回node的列表\n",
    "                # 谓词也学SO搞个idx到span的映射，处理并列的情况\n",
    "                # return node\n",
    "                return node_list\n",
    "            else:\n",
    "                # start = find_smallest(dep_T2H, anchor)\n",
    "                # node = Node(start, anchor)\n",
    "                # node = [start, anchor]\n",
    "                node = idx_so_span.get(anchor, None)\n",
    "                if node[-1]!='node': node.append('node')\n",
    "                return [node]\n",
    "\n",
    "        def get_recur_trip(preda):\n",
    "            '''\n",
    "            得到带有递归节点的三元组\n",
    "            anchor有COO：甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站\n",
    "            从句有COO：建筑的防火应符合下列目标要求：保障人身生命和财产安全、人身健康；\n",
    "            '''\n",
    "            flag, head, tail = self.bi_subj(preda, seg, pos)\n",
    "\n",
    "            if not flag:\n",
    "                anchor = get_head_anchor(preda[0])\n",
    "                head = get_node(anchor)\n",
    "\n",
    "                for p in preda:                         # 存在补语加VOB的情况：我们应看完饭、吃完饭、做完饭\n",
    "                    anchor = get_tail_anchor(p)\n",
    "                    if anchor!=-1: break\n",
    "                tail = get_node(anchor)\n",
    "\n",
    "            # 有多个head或tail则做笛卡尔积\n",
    "            if preda[-1]!='node': preda.append('node')\n",
    "            trip_list = []\n",
    "            '''\n",
    "            如果head和tail是node则要解析其定语\n",
    "                有谓语则解析句子，没谓语则当作节点定语\n",
    "            针对preda解析其状语，句子以句号为分隔\n",
    "                有谓语则解析句子，没谓语则当节点状语\n",
    "            可以先不处理定语\n",
    "            基本节点的格式为：{\n",
    "                trip: [h, preda, t],\n",
    "                modi_h: [node, cell],\n",
    "                modi_t: [node, cell],\n",
    "                adv: [node, cell]\n",
    "            }\n",
    "            '''\n",
    "            adv_list = []\n",
    "            for adv_anchor in dep_T2H:\n",
    "                pass\n",
    "            for h in head:\n",
    "                for t in tail:\n",
    "                    trip_list.append([h,preda,t])\n",
    "            return trip_list\n",
    "\n",
    "        trip_spans = []\n",
    "        print('510', hed_spans)\n",
    "        for preda in hed_spans:\n",
    "            '''\n",
    "            根据谓词判断三元组，借助COO处理省略主语的情况\n",
    "            头实体：先找SBV、FOB，没有则顺着COO找，没有则用上级条文的主语\n",
    "            尾实体：找VOB，没有则记占位节点\n",
    "            仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定\n",
    "            连词相连的谓词要先合并再拆解\n",
    "            仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定\n",
    "            如果anchor处是从句的谓语，则递归执行该函数\n",
    "            '''\n",
    "            trip_spans += get_recur_trip(preda)\n",
    "        \n",
    "        '''在这里给'''\n",
    "        print(trip_spans)\n",
    "\n",
    "        def get_str(spans):\n",
    "            '''递归得到字符串'''\n",
    "            spans_str = []\n",
    "            for s in spans:\n",
    "                # print('414', s)\n",
    "                # if len(s)==3:\n",
    "                if not s:\n",
    "                    span_str = []\n",
    "                elif s[-1]=='tri':\n",
    "                    span_str = get_str(s[:-1])\n",
    "                elif s[-1]!='node':\n",
    "                    span_str = get_str(s)\n",
    "                else:\n",
    "                    span_str = seg[s[0]-1:s[1]]\n",
    "                spans_str.append(span_str)\n",
    "            return spans_str\n",
    "        \n",
    "        phrases = [\n",
    "            get_str(trip_span) for trip_span in trip_spans\n",
    "        ]\n",
    "        print('single trip phrases', phrases)\n",
    "        print(trip_spans)\n",
    "        return trip_spans\n",
    "\n",
    "    \n",
    "    def deal_digestion(self):\n",
    "        '''\n",
    "        确定其的指代内容\n",
    "        做三元组成分，则替换为对应的名词短语\n",
    "        做修饰语，则替换为名词短语+的\n",
    "        指代判定依据：前一个名词短语或三元组的头\n",
    "            所有最基本的头尾节点都要经过指代消解\n",
    "        做修饰语：陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；\n",
    "        做三元组成分：建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能；\n",
    "        远距离指代：设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道\n",
    "        '''\n",
    "        \n",
    "    def deal_attribute():\n",
    "        '''\n",
    "        处理开头是介词的，之间、间距、距离\n",
    "        短语开头是介词：消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。\n",
    "        短语结尾是之间、间距、距离：甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及与其他建筑的间距，应符合消防安全要求；\n",
    "        短语开头是介词，结尾是间距：易燃易爆危险品库房与在建工程的防火间距不应小于15m，与固定动作作业区不应小于12m，与邻近人员密集区、建筑物相对集中区及其他建筑的间距应符合消防要求；\n",
    "        省略属性，属性值的头实体应该是属性\n",
    "        '''\n",
    "\n",
    "    def split_phrase():\n",
    "        '''\n",
    "        分割名词短语\n",
    "        把部位当作属性节点\n",
    "        先把逗号分开，再按照一般拆解过程来\n",
    "        '''\n",
    "\n",
    "    def get_modi():\n",
    "        '''\n",
    "        定语从句，谓词是ATT的尾，向前向后找全覆盖\n",
    "        中心语用连续ATT和ADV确定范围\n",
    "        面积大于100平米的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。\n",
    "        实体的定语还是在关系节点上，内边上不附着定语或状语\n",
    "        '''\n",
    "    \n",
    "    def get_adv_trip():\n",
    "        '''\n",
    "        解析状语从句\n",
    "        情态动词可能在一个状语之前：水处理药剂必须计量投加。\n",
    "        '''\n",
    "    \n",
    "    def get_modi_trip():\n",
    "        '''解析定语从句'''\n",
    "\n",
    "'''\n",
    "把“压强”换成“压力”，解析完后再换回来\n",
    "词典缺失词替换\n",
    "提取带定语的名词短语\n",
    "提取谓词、状语\n",
    "提取三元组，状语内的名词短语不参与三元组构建\n",
    "嵌套提取主语从句、宾语从句中的三元组\n",
    "\n",
    "名词短语处理：\n",
    "共指消解，其\n",
    "处理双头属性，开头是介词的，之间、间距、距离\n",
    "\n",
    "名词短语解析，提取定语，定语分配给各个并列中心语\n",
    "定语分为修饰、从句、实体\n",
    "解析定语从句\n",
    "中心语分类，哪些是实体，哪些是属性\n",
    "解析一般实体，实体-包含-实体\n",
    "解析一般属性，实体-内边-属性\n",
    "处理省略实体、省略属性的属性，属性值之前必是属性\n",
    "拆解并列中心语\n",
    "'''\n",
    "\n",
    "rule_ner = RuleNER(ltp)\n",
    "txt = '建筑的选址和总平面布局应符合减小火灾危害，方便灭火救援的要求，并应符合下列规定'\n",
    "# txt = '生产和储存易燃易爆物品的工厂、仓库等应位于城镇规划区的边缘或相对独立的安全地带；'\n",
    "# txt = '储罐区的低倍数泡沫灭火系统应符合下列规定：对于非水溶性甲、乙、丙类液体固定顶储罐，应为液上喷射、液下喷射或半液下喷射系统；'\n",
    "txt = '甲、乙类工厂和仓库，可燃气体充装站、供应站和调压站，汽车加油加气站等之间及和其他建筑的间距，应符合消防安全要求；'\n",
    "# txt = '消防站执勤车辆的主出入口距离大型人员密集的公共建筑的主要疏散出口不应小于50m。'\n",
    "'''如果开头词性是p，则有可能表示属性，实体末尾是之间、距离，则要当相对属性来处理'''\n",
    "txt = '陆上消防站应位于易燃易爆危险品场所或设施的常年主导风向的上风或侧风处，其用地边界距离甲、乙类厂房、加油、加气站及易燃易爆危险品储存场所不应小于50m；'\n",
    "txt = '建筑内的防火分隔应能在其设计耐火时间内阻止火势与烟气蔓延至其他区域'\n",
    "txt = '设置泄压设施时，泄压部位应能在爆炸作用达到结构最大耐受压强前泄压，其泄压方向不应朝向人员聚集的场所和人行通道；'\n",
    "# txt = '除粮食等筒仓外，无法设置泄压设施或泄压面积不符合要求时，相应部位的建筑承重结构和防火分隔结构应满足抗爆要求。'\n",
    "'''有没有介词会很影响状语的抽取规则'''\n",
    "txt = '当仓库足够大时，仓库的防火要求应根据储存物质的性质和储存物质中可燃物的数量等因素确定，并应符合下列规定：'\n",
    "txt = '仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定'\n",
    "# txt = '仓库不应设在居住区内部'\n",
    "txt = '保障施工现场消防供水的消防水泵配电应能在火灾时保持不间断供电，其线路应为专用消防配电线路。'\n",
    "# txt = '戊类仓库的防火要求'\n",
    "# txt = '建筑承重结构应保证其在受到火或高温作用后仍能在设计耐火时间内正常发挥功能'\n",
    "txt = '甲、乙类工厂和仓库应设在可燃气体充装站、供应站和调压站、加油站'\n",
    "txt = '当温度大于或明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器'\n",
    "# txt = '温度大于30，湿度大于50'\n",
    "# txt = '当温度大于30或高度明显等于30，湿度大于50时，体育场要打开抽湿器，关闭加热器'\n",
    "# txt = '建筑的防火应符合下列目标要求：保障生命财产安全和身体健康；'\n",
    "txt = '当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器'\n",
    "# txt = '仓库应根据储存物质的性质和储存物质中可燃物的数量等因素确定和规划防火要求，并应符合下列规定'\n",
    "# txt = '为了预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求，依据有关法律、法规，制定本规范。'\n",
    "# txt = '新建、改建和扩建建筑在规划、设计、施工与使用中的防火技术与措施，应遵守本规范。' # 有两个SBV\n",
    "txt = '当建筑防火中采用的方法、技术、材料与制品、措施等与本规范的规定不同或有特殊要求时，应根据本规范第2.1节进行合规性判定。'\n",
    "txt = '当方法与制品等与规定不同或有特殊要求时，应根据本规范第2.1节进行合规性判定。'\n",
    "# txt = '建筑防火中采用的方法、技术、材料与制品、措施等与本规范的规定不同或有特殊要求'\n",
    "# txt = '无障碍设施应保证安全和各类人群的方便使用。'\n",
    "# txt = '本规范适用于新建、扩建、改建的民用与工业建筑中自动喷水灭火系统的设计。'\n",
    "# txt = '本规范要预防建筑火灾和减少火灾危害，确保生命财产的安全，并在建筑防火中贯彻执行国家技术经济政策，确保建筑的防火符合安全可靠、经济合理、技术先进、确保质量的要求'\n",
    "# txt = '建筑中散发较空气重的可燃气体、蒸气或有粉尘、纤维爆炸危险的场所或部位应符合下列规定'\n",
    "# txt = '瓶装液化石油气不应与其他化学危险物品混放；'\n",
    "# txt = '生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触'\n",
    "# txt = '新建、改建或拆除建筑、结构、设备或类似活动所用临时电气线路和照明器具、涉及施工所需的易燃和可燃物质的使用与存放以及施工现场的用火、用电、用气应符合消防安全要求。'\n",
    "# txt = '地下、半地下场所内不应使用或储存液化石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道。'\n",
    "# txt = '地下、半地下场所内不应使用或储存液化石油气、可燃气体、液体燃料，不应有燃气或可燃液体配送管道。'\n",
    "# txt = '相对密度不小于0.75的可燃气体'\n",
    "txt = '施工临时办公与生活用房、发电机房、变配电站、厨房操作间、锅炉房和可燃材料与易燃易爆物品库房，当采用金属夹芯板材时，其芯材的燃烧性能应为A级。'\n",
    "########## 符合表会被认为是一个词 ##########\n",
    "txt = '城乡给水工程建设规模的划分应符合表2.0.23的要求'  # 符合替换为满足\n",
    "# txt = '城乡给水工程建设规模的划分应按照表2.0.23的要求设置'\n",
    "txt = '给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求'\n",
    "res = rule_ner.get_spd(txt)\n",
    "word_pos = list(zip(res[0], res[1], res[2]))\n",
    "# print(word_pos)\n",
    "# print(res[2])\n",
    "# rule_ner.get_full_trips(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 括号删除函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原料库房与设备间均应有保持良好通风的设备，换气次数应为8~12次/h\n",
      "大面积的多层地下建筑物\n",
      "复杂地质条件下的坡上建筑物\n",
      "基坑工程、边坡工程设计时，应根据支护结构破坏可能产生的后果的严重性，采用不同的安全等级。\n",
      "支护结构安全等级的划分应符合表 2.2.4 的规定。\n",
      "所有建筑物的地基计算均应满足承载力要求；\n",
      "土和水对建筑材料的腐蚀性；\n"
     ]
    }
   ],
   "source": [
    "def del_brackets(txt, seg, pos, dep):\n",
    "    '''\n",
    "    返回删掉括号中内容的句子\n",
    "    括号中是修饰后续内容的数值则保留括号里内容\n",
    "        原料库房与设备间（3）均应有保持良好通风的设备，换气次数应为（8~12）次/h\n",
    "    '''\n",
    "    if '（' not in txt:                                 # 原文中没有括号\n",
    "        return txt\n",
    "    txt_flag = False\n",
    "    if '（' not in seg:                                 # 分词错误导致分词结果中没有括号\n",
    "        seg = txt\n",
    "        txt_flag = True\n",
    "    len_s = len(seg)\n",
    "    del_list = [False] * len_s\n",
    "    flag = False\n",
    "    for i in range(len_s-1):\n",
    "        if seg[i]=='（':\n",
    "            del_list[i] = True\n",
    "            if not txt_flag:\n",
    "                if pos[i+1]=='m' and dep[i+1][1]>i+2:   # 括号中是修饰后续内容的数值则保留括号里内容\n",
    "                    continue\n",
    "            flag = True\n",
    "        elif seg[i]=='）':\n",
    "            del_list[i] = True\n",
    "            flag = False\n",
    "        else:\n",
    "            del_list[i] = flag\n",
    "    if seg[-1] in '（）': del_list[-1] = True\n",
    "    new_seg = [seg[i] for i in range(len_s) if not del_list[i]]\n",
    "    return ''.join(new_seg)\n",
    "\n",
    "txts = [\n",
    "    '原料库房与设备间（3）均应有保持良好通风的设备，换气次数应为（8~12）次/h',\n",
    "    '大面积的多层地下建筑物（如地下车库、商场、运动场等）',\n",
    "    '复杂地质条件下的坡上建筑物（包括高边坡）',\n",
    "    '基坑工程、边坡工程设计时，应根据支护（挡）结构破坏可能产生的后果（危及人的生命、造成经济损失、对社会或环境产生影响等）的严重性，采用不同的安全等级。',\n",
    "    '支护（挡）结构安全等级的划分应符合表 2.2.4 的规定。',\n",
    "    '所有建（构）筑物的地基计算均应满足承载力要求；',\n",
    "    '土和（或）水对建筑材料的腐蚀性；'\n",
    "]\n",
    "for txt in txts:\n",
    "    seg, pos, dep = rule_ner.get_spd(txt)\n",
    "    new_txt = del_brackets(txt, seg, pos, dep)\n",
    "    print(new_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取“的”引导的定语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "131 [[1, 5], [8, 12], [14, 15], [18, 19]]\n",
      "['原料', '库房', '与', '设备', '间']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17560\\1087259845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mspan\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mso_spans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mget_u_att\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# print(new_txt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17560\\1087259845.py\u001b[0m in \u001b[0;36mget_u_att\u001b[1;34m(span, seg, pos, dep)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mspan_T2H\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_T2H\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0matt_span_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "# %aimport KPR\n",
    "import KPR\n",
    "\n",
    "def get_u_att(span, seg, pos, dep):\n",
    "    '''\n",
    "    找到一定范围内所有“的”引导的定语\n",
    "    return:\n",
    "        [[开始位置，结束位置，定语的牵引点位置，中心语位置]]\n",
    "    '''\n",
    "    if not span: span=[1, len(seg)]\n",
    "    start, end = span[0], span[1]\n",
    "    span_T2H = build_T2H(dep[start-1:end])\n",
    "    att_span_list = []\n",
    "    i = end-1\n",
    "    while i>=start:\n",
    "        if seg[i]=='的':\n",
    "            att_start = find_smallest(span_T2H, dep[i][1])\n",
    "            if pos[att_start-1]=='wp': att_start+=1\n",
    "            center = dep[dep[i][1]-1][1]\n",
    "            att_span_list.append([att_start, i, dep[i][1], center])\n",
    "            i = att_start - 1\n",
    "        i -= 1\n",
    "    # phrases = [[seg[s[0]-1:s[1]], seg[s[2]-1], seg[s[3]-1]] for s in att_span_list]\n",
    "    # if phrases:\n",
    "    #     print('u_att phrases', phrases)\n",
    "    return att_span_list\n",
    "\n",
    "txts = [\n",
    "    '原料库房与设备间（3）均应有保持良好通风的设备，换气次数应为（8~12）次/h',\n",
    "    '基坑工程、边坡工程设计时，应根据支护（挡）结构破坏可能产生的后果（危及人的生命、造成经济损失、对社会或环境产生影响等）的严重性，采用不同的安全等级。',\n",
    "    '支护（挡）结构安全等级的划分应符合表 2.2.4 的规定。',\n",
    "    '所有建（构）筑物的地基计算均应满足承载力要求；',\n",
    "    '当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器',\n",
    "    '给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求',\n",
    "    '保养厂应能承担营运车辆的高级保养任务及相应的配件加工、修制和修车材料、燃料的储存、发放等',\n",
    "    '控制中心应具备行车调度、电力调度、环境与设备调度、防灾指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度和指挥功能，并应对城市轨道交通系统运营的全过程进行集中监控和管理',\n",
    "    '给水厂应对制水生产中的主要设施、设备制定和实施巡查维护保养制度，应对主要工艺运行情况及其运行中的动态技术参数，制定和实施质量控制点检验制度',\n",
    "    '建筑无法设置泄压设施或泄压面积不符合要求时，建筑中存在可燃气体、蒸气、粉尘或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。',\n",
    "    '建筑中存在可燃气体、蒸气、粉尘或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。',\n",
    "]\n",
    "# 去除括号中的文本，抽取定中短语中“的”引导的定语\n",
    "for txt in txts:\n",
    "    seg, pos, dep = rule_ner.get_spd(txt)\n",
    "    new_txt = del_brackets(txt, seg, pos, dep)\n",
    "    if new_txt:\n",
    "        seg, pos, dep = rule_ner.get_spd(new_txt)\n",
    "    else:\n",
    "        new_txt = txt\n",
    "    dep_T2H = build_T2H(dep)\n",
    "    so_spans = KPR.get_so(seg, pos, dep, dep_T2H)\n",
    "    # print('txt', new_txt)\n",
    "    for span in so_spans:\n",
    "        print(seg[span[0]-1:span[1]])\n",
    "        get_u_att(span, seg, pos, dep)\n",
    "    # print(new_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2022-12-14 20:12:03.895 | DEBUG    | text2vec.sentence_model:__init__:74 - Use device: cpu\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from gensim.models import KeyedVectors\n",
    "from model_TS import TxtSim\n",
    "word_vec_tenc = 'D:\\Download\\ArchData\\data\\PreData\\\\arch-zh-d200-tencent-tp200.txt'\n",
    "wv_from_text_word = KeyedVectors.load_word2vec_format(\n",
    "    word_vec_tenc, binary=False, no_header=False)\n",
    "\n",
    "from text2vec import SBert\n",
    "sbert = SBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "# %aimport KPR\n",
    "import KPR\n",
    "word_sim = TxtSim(wv_from_text_word, jieba, sbert)\n",
    "k_spliter = KPR.WordSpliter(ltp, word_sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 并列部分的分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "368 保养厂应能承担高级保养任务及相应的配件加工、修制和修车材料、燃料的储存\n",
      "380 保养厂应能承担高级保养任务及相应的配件加工和材料、燃料的储存\n",
      "131 [[1, 1], [5, 18]]\n",
      "380 保养厂应能承担高级保养任务及相应的配件加工和材料、燃料的储存\n",
      "131 [[1, 1], [5, 18]]\n",
      "380 保养厂应能承担高级保养任务及相应的配件加工和材料、燃料的储存\n",
      "131 [[1, 1], [5, 18]]\n",
      "382 保养厂应能承担高级保养任务及相应的配件加工和材料的储存\n",
      "393 inter_cache {'distill_0': {'seg': ['保养厂', '应', '能', '承担', '高级', '保养', '任务', '及', '相应', '的', '配件', '加工', '、', '修制', '和', '修车', '材料', '、', '燃料', '的', '储存'], 'del_indic': [False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, False, False, False, False, False], 'ellip_dic': defaultdict(<class 'dict'>, {12: {'scoo': [13, 14]}, 17: {'svatt': [16, 16]}})}, 'distill_1': {'seg': ['保养厂', '应', '能', '承担', '高级', '保养', '任务', '及', '相应', '的', '配件', '加工', '和', '材料', '、', '燃料', '的', '储存'], 'del_indic': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'ellip_dic': defaultdict(<class 'dict'>, {})}, 'distill_2': {'seg': ['保养厂', '应', '能', '承担', '高级', '保养', '任务', '及', '相应', '的', '配件', '加工', '和', '材料', '、', '燃料', '的', '储存'], 'del_indic': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'ellip_dic': defaultdict(<class 'dict'>, {})}, 'distill_3': {'seg': ['保养厂', '应', '能', '承担', '高级', '保养', '任务', '及', '相应', '的', '配件', '加工', '和', '材料', '、', '燃料', '的', '储存'], 'del_indic': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False], 'ellip_dic': defaultdict(<class 'dict'>, {14: {'scoo': [15, 16]}})}}\n",
      "131 [[1, 1], [5, 16]]\n",
      "401 word_pos [('保养厂', 'n', (1, 4, 'SBV')), ('应', 'v', (2, 4, 'ADV')), ('能', 'v', (3, 4, 'ADV')), ('承担', 'v', (4, 0, 'HED')), ('高级', 'a', (5, 6, 'ADV')), ('保养', 'v', (6, 7, 'ATT')), ('任务', 'n', (7, 4, 'VOB')), ('及', 'c', (8, 12, 'LAD')), ('相应', 'v', (9, 12, 'ATT')), ('的', 'u', (10, 9, 'RAD')), ('配件', 'n', (11, 12, 'FOB')), ('加工', 'v', (12, 7, 'COO')), ('和', 'c', (13, 16, 'LAD')), ('材料', 'n', (14, 16, 'ATT')), ('的', 'u', (15, 14, 'RAD')), ('储存', 'v', (16, 7, 'COO'))]\n",
      "405 [[1, 3], [5, 10], [12, 12]]\n",
      "406 [[['高级', '保养', '任务']], [['相应', '的', '配件', '加工', '和', '材料']], [['储存']]]\n"
     ]
    }
   ],
   "source": [
    "# 确定这一整段都是并列的实体或是含并列的定语后执行\n",
    "'''\n",
    "只有“的”引导的定语和原生紧邻coo存在分配现象\n",
    "放在条文预处理：\n",
    "    儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室和病房、教学建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    地下、半地下场所内不应使用或储存液化石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道\n",
    "0.连续并列合并（全文范围内的合并，包括动词并列）；去掉纯短vatt：父节点只允许有wp和att，且是att中第一个，att向外只允许有wp，且父节点不是别人的att\n",
    "    儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室、教学建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    地下、半地下场所内不应使用石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道\n",
    "放在给定span的条文蒸馏\n",
    "0.去掉无用的等；去掉“的”引导的孤立定语，定语前没有连词非连词定语、定语是从句或定语由方位名词引导\n",
    "    儿童活动场所、老年人活动场所、治疗室、教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "1.去掉短vatt：父节点只允许有wp和att，且att向外只允许有wp，连续att关系（最近的要是v）、都是短att且相邻（最近的要是v）\n",
    "    场所、场所、治疗室、用房位于走道尽端时，其疏散门不应少于2个\n",
    "2.连续合并，必须是在原句中前面没有修饰语的/拆开时若对应单词有自己的修饰则不会继承第一个的修饰\n",
    "    场所位于走道尽端时，其疏散门不应少于2个\n",
    "\n",
    "    对出水水质产生影响的化学药剂的加注设备应配置备用设备。\n",
    "    保养厂应能承担营运车辆的高级保养任务及相应的配件加工、修制和修车材料、燃料的储存、发放等\n",
    "    儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室和病房、教学建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    地下、半地下场所内不应使用或储存液化石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道。\n",
    "0.连续并列合并（全文范围内的合并，包括动词并列），去掉短vatt，去掉无用的等：父节点只允许有wp和att，且att向外只允许有wp\n",
    "    对水质产生影响的化学药剂的加注设备应配置设备。\n",
    "    保养厂应能承担车辆的高级保养任务及相应的配件加工、修制和修车材料、燃料的储存\n",
    "    活动场所、设施中的老年人活动场所、建筑中的治疗室、建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    给水厂的设计规模应满足范围规定内最高日的用水量、企业用水量、道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    地下、半地下场所内不应使用或储存石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道。\n",
    "1.去掉“的”引导的非连词定语、定语从句和由方位名词引导的直接去除\n",
    "    对水质产生影响的化学药剂的设备应配置设备。\n",
    "    保养厂应能承担高级保养任务及相应的配件加工、修制和修车材料、燃料的储存\n",
    "    活动场所、老年人活动场所、治疗室、教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    给水厂的设计规模应满足用水量、企业用水量、道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    地下、半地下场所内不应使用或储存石油气、可燃气体、液体燃料，不应有相应的燃气或可燃液体配送管道。\n",
    "2.连续合并，必须是在原句中前面没有修饰语的/拆开时若对应单词有自己的修饰则不会继承第一个的修饰\n",
    "    对水质产生影响的化学药剂的设备应配置设备。\n",
    "    保养厂应能承担高级保养任务及相应的配件加工和修车材料、燃料的储存\n",
    "    活动场所、老年人活动场所、教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    给水厂的设计规模应满足用水量、企业用水量、道路用水量、管网漏损水量及未预见用水量的要求\n",
    "    地下、半地下场所内不应使用或储存石油气、可燃气体、液体燃料，不应有相应的燃气或可燃液体配送管道。\n",
    "3.去掉短vatt\n",
    "\n",
    "相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料\n",
    "可燃气体、液体燃料\n",
    "\n",
    "存在连词或顿号时才执行下述步骤\n",
    "    给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    保养厂应能承担营运车辆的高级保养任务及相应的配件加工、修制和修车材料、燃料的储存、发放等\n",
    "    控制中心应具备行车调度、电力调度、环境与设备调度、防灾指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度和指挥功能，并应对城市轨道交通系统运营的全过程进行集中监控和管理\n",
    "    给水厂应对制水生产中的主要设施、设备制定和实施巡查维护保养制度，应对主要工艺运行情况及其运行中的动态技术参数，制定和实施质量控制点检验制度\n",
    "    建筑中存在可燃气体、蒸气、粉尘或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。\n",
    "1.去掉“的”引导的长定语、“的”引导的动词短定语-所有定语都是动词，去掉无用的“等”，连续并列合并，去掉“ATT”引导的动词短定语-只有连续挨着中心词的定语\n",
    "1.去掉“的”引导的长定语，去掉无用的“等”，连续并列合并，去掉“ATT”引导的动词短定语-只有连续挨着中心词的定语\n",
    "1.去掉“的”引导的孤立定语，去掉无用的“等”，去掉“ATT”引导短定语-没有出边且父节点不是定语，连续并列合并\n",
    "    给水厂的设计规模应满足综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    保养厂应能承担车辆的高级保养任务及配件加工、修制和修车材料、燃料的储存\n",
    "    控制中心应具备行车调度、电力调度、环境与设备调度、防灾指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度功能，并应对全过程进行集中监控\n",
    "    建筑中存在可燃气体或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。\n",
    "2.去掉“ATT”引导的短定语-不是状语且连续，连续并列合并(直接COO且都是单词)，去掉短定语(只有一个单词定语)\n",
    "    给水厂的设计规模应满足用水量、工业企业用水量、道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
    "    保养厂应能承担高级保养任务及配件加工、修制和材料、燃料的储存\n",
    "    控制中心应具备行车调度、电力调度、环境与设备调度、指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度功能，并应对全过程进行集中监控\n",
    "    建筑中存在气体或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。\n",
    "3.连续并列合并\n",
    "    给水厂的设计规模应满足用水量、工业企业用水量、道路用水量、管网漏损水量及未预见用水量的要求\n",
    "    保养厂应能承担高级保养任务及配件加工和材料的储存\n",
    "    控制中心应具备行车调度、电力调度、环境与设备调度、指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度功能，并应对全过程进行集中监控\n",
    "    建筑中存在气体爆炸危险的部位的建筑承重结构应满足抗爆要求。\n",
    "4.用现有方法做并列解析\n",
    "\n",
    "底层得到树状解析结果后，往上找每个中心语在上层对应的词语\n",
    "    有vatt则则给到单个中心语\n",
    "    有coo则记在当前中心语的名下\n",
    "    有uatt：\n",
    "        只有一个且在同一层次的句首，则分配给该层次的每个节点\n",
    "        多个或不在句首，则只修饰对应节点\n",
    "\n",
    "'''\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "# %aimport KPR\n",
    "import KPR\n",
    "\n",
    "def have_dep(idx, tag, dep, dep_T2H):\n",
    "    '''判断当前词是否做对应成分'''\n",
    "    f1 = tag in dep_T2H[idx+1]\n",
    "    f2 = False\n",
    "    if dep[idx][2] == 'COO':\n",
    "        f2 = have_dep(dep[idx][1]-1, tag, dep, dep_T2H)\n",
    "    if f1 and tag == 'FOB':\n",
    "        fob = dep_T2H[idx+1][tag][0]\n",
    "        f3 = fob<idx\n",
    "        return (f1 and f3) or f2\n",
    "    else:\n",
    "        return f1 or f2\n",
    "\n",
    "def is_preda_of_clause(anchor, dep, dep_T2H):\n",
    "    '''判断当前词是否为从句的谓词'''\n",
    "    f1 = pos[anchor-1] in ['v','p']\n",
    "    f2 = False\n",
    "    for tag in ['SBV','FOB','VOB']:\n",
    "        if have_dep(anchor-1, tag, dep, dep_T2H):\n",
    "            f2 = True\n",
    "            break\n",
    "    return f1 and f2\n",
    "\n",
    "def is_simple_uatt(uatt_span, dep):\n",
    "    '''\n",
    "    判断是否为简单uatt\n",
    "    长度不大于3 且 (“的”的上级节点是左边第一个 或 内部关系都是COO、ATT)\n",
    "    需要COO判断的情况：修车材料、做饭燃料的储存、发放等\n",
    "    '''\n",
    "    u_s = uatt_span[0]\n",
    "    u_e = uatt_span[1]\n",
    "    f1 = u_e-u_s<=2\n",
    "    if not f1: return f1\n",
    "    f2 = dep[u_e][1]==u_e\n",
    "    if f2: return f1 and f2\n",
    "    f3 = all([dep[i][2] in ['COO','ATT'] for i in range(u_s-1, u_e)])\n",
    "    return f1 and (f2 or f3)\n",
    "\n",
    "def is_isolated_uatt(uatt_span, seg, pos, dep, dep_T2H):\n",
    "    '''\n",
    "    判断是否为孤立uatt\n",
    "    定语的前一个词既不是连词也不是顿号\n",
    "    当前定语由方位名词引导\n",
    "    当前定语是定语从句\n",
    "    '''\n",
    "    u_s, u_e = uatt_span[0], uatt_span[1]\n",
    "    f1 = u_s>1 and seg[u_s-2]!='、' and pos[u_s-2]!='c'\n",
    "    f2 = pos[u_e-1]=='nd'\n",
    "    f3 = is_preda_of_clause(uatt_span[2], dep, dep_T2H)\n",
    "    return f1 or f2 or f3\n",
    "\n",
    "def is_pure_short_att(idx, dep, dep_T2H):\n",
    "    '''\n",
    "    判断是否为短定语\n",
    "    中心语只有这一个定语且和中心语相邻\n",
    "    去掉“ATT”引导的动词短定语-只有连续挨着中心词的定语\n",
    "    f1: 跟父节点是修饰关系且父节点是下一个词\n",
    "    f2: 父节点只有这么一个修饰语\n",
    "    f3: 除了标点没有向外的箭头\n",
    "    f4: 父节点不是状语\n",
    "    '''\n",
    "    f1 = dep[idx][2]=='ATT' and dep[idx][1]==idx+2\n",
    "    if not f1: return f1\n",
    "    f2 = len(dep_T2H[dep[idx][1]].get('ATT', []))==1\n",
    "    if not f2: return f1 and f2\n",
    "    f3 = not dep_T2H[idx+1] or list(dep_T2H[idx+1].keys())==['WP']\n",
    "    if not f3: return f1 and f2 and f3\n",
    "    f4 = dep[dep[idx][1]-1][2]!='ADV'\n",
    "    return f1 and f2 and f3 and f4\n",
    "\n",
    "def get_general_short_vatt(idx, pos, dep, dep_T2H):\n",
    "    '''\n",
    "    以每个词为中心向前找svatt的范围\n",
    "    中心语只有这一个定语且和中心语相邻\n",
    "    去掉“ATT”引导的动词短定语-只有连续挨着中心词的定语\n",
    "    f1: 不是状语\n",
    "    f2: 前一个词是v且是att\n",
    "    f3: 所有att都只有向前的att\n",
    "    f4: att的边界连续\n",
    "    '''\n",
    "    f1 = dep[idx][2]!='ADV'\n",
    "    if not f1: return []\n",
    "    f2 = idx>0 and pos[idx-1]=='v' and dep[idx-1]==[idx,idx+1,'ATT']\n",
    "    if not f2: return []\n",
    "    att_list = dep_T2H[idx+1].get('ATT', [])\n",
    "    f3_list = []\n",
    "    att_spans = []\n",
    "    legal_keys = [{}, {'WP'}, {'ATT'}, {'WP','ATT'}]\n",
    "    for j in att_list:\n",
    "        keys = set(list(dep_T2H[j].keys()))\n",
    "        if not keys in legal_keys:\n",
    "            f3_list.apend(False)\n",
    "            break\n",
    "        start = j\n",
    "        for k in range(j-2,-1,-1):\n",
    "            keys = set(list(dep_T2H[j].keys()))\n",
    "            flag = dep[k]==[k+1,k+2,'ATT'] and keys in legal_keys\n",
    "            if not flag:\n",
    "                f3_list.append(False)\n",
    "                break\n",
    "            if flag and keys in legal_keys[:2]:\n",
    "                f3_list.append(True)\n",
    "                start = j + 1\n",
    "                break\n",
    "        if not f3_list[-1]: break\n",
    "        att_spans.append([start,j])\n",
    "    if not all(f3_list): return []\n",
    "    if not att_spans: return []\n",
    "    if len(att_spans)==1: return att_spans[0]\n",
    "    for j in range(len(att_spans)-1):\n",
    "        if att_spans[j+1][0]-att_spans[j][1]>1: return []\n",
    "    return [att_spans[0][0], att_spans[-1][-1]]\n",
    "\n",
    "def get_continum_short_coord_span(span, seg, dep_T2H):\n",
    "    '''\n",
    "    找到连续短并列结构的范围\n",
    "    都是单个词，间隔只有顿号或连词\n",
    "    间隔必须是同一个，连续顿号或者连续某个连词\n",
    "    '''\n",
    "    if not span: span = [1, len(seg)]\n",
    "    i = span[0]-1\n",
    "    short_coo_spans = []\n",
    "    while i<span[1]:\n",
    "        coos = dep_T2H[i+1].get('COO', [])              # 并列的内容都会标在第一个的后面\n",
    "        p = i + 1\n",
    "        if coos: \n",
    "            conj = seg[i+1]\n",
    "            # print(i, seg[i], dep_T2H[i+1])\n",
    "            for c in coos:\n",
    "                # print('99', c, seg[c-1])\n",
    "                if c-p==2 and seg[p]==conj:             # 中间只隔一个词且该词是第一个连词\n",
    "                    p = c\n",
    "                else:\n",
    "                    break\n",
    "            if p>i+1:                                   # 只记录连续短并列结构\n",
    "                short_coo_spans.append([i+1, p])\n",
    "                i = c\n",
    "            else:\n",
    "                i = c-1\n",
    "        else:\n",
    "            i += 1\n",
    "    return short_coo_spans\n",
    "\n",
    "'''\n",
    "只有“的”引导的定语和原生紧邻coo存在分配现象\n",
    "放在条文预处理：\n",
    "    儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室和病房、教学建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    地下、半地下场所内不应使用或储存液化石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道\n",
    "0.连续并列动词合并（全文范围内的合并，包括动词并列）；去掉纯短vatt：父节点只允许有wp和att，且是att中第一个，att向外只允许有wp，且父节点不是别人的att\n",
    "    儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室、教学建筑中的教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "    地下、半地下场所内不应使用石油气、相对密度不小于0.75的可燃气体、闪点低于60℃的液体燃料，不应有相应的燃气或可燃液体配送管道\n",
    "放在给定span的条文蒸馏\n",
    "1.去掉无用的等；去掉“的”引导的孤立定语，定语前没有连词非连词定语、定语是从句或定语由方位名词引导\n",
    "    儿童活动场所、老年人活动场所、治疗室、教学用房位于走道尽端时，其疏散门不应少于2个\n",
    "2.去掉短vatt：父节点只允许有wp和att，且att向外只允许有wp，连续att关系（最近的要是v）、都是短att且相邻（最近的要是v）\n",
    "    场所、场所、治疗室、用房位于走道尽端时，其疏散门不应少于2个\n",
    "3.连续合并，必须是在原句中前面没有修饰语的/拆开时若对应单词有自己的修饰则不会继承第一个的修饰\n",
    "    场所位于走道尽端时，其疏散门不应少于2个\n",
    "'''\n",
    "\n",
    "def show_spd(seg, pos, dep, tag='246'):\n",
    "    word_pos = list(zip(seg, pos, dep))\n",
    "    print(f'{tag} word_pos', word_pos)\n",
    "\n",
    "def distill_0(span, seg, pos, dep, dep_T2H, del_indic, ellip_dic):\n",
    "    '''\n",
    "    连续并列合并\n",
    "    去掉纯短vatt\n",
    "    '''\n",
    "    if not span: span=[1,len(seg)]\n",
    "    # 合并连续短并列\n",
    "    short_coo_spans = get_continum_short_coord_span(span, seg, dep_T2H)\n",
    "    for coo_span in short_coo_spans:\n",
    "        start, end = coo_span\n",
    "        # print('253', span, coo_span)\n",
    "        del_indic[start:end] = [True]*(end-start)\n",
    "        ellip_dic[start]['scoo'] = [start+1, end]\n",
    "    # 去掉纯短vatt\n",
    "    for i in range(span[0]-1, span[1]):\n",
    "        if not del_indic[i]:\n",
    "            flag = is_pure_short_att(i, dep, dep_T2H) and pos[i]=='v'\n",
    "            del_indic[i] = flag\n",
    "            if flag:\n",
    "                # print('268 短定语', i, flag, seg[i])\n",
    "                ellip_dic[i+2]['svatt'] = [i+1, i+1]\n",
    "\n",
    "def distill_1(span, seg, pos, dep, dep_T2H, del_indic, ellip_dic):\n",
    "    ''''''\n",
    "    # 去掉“的”引导的孤立定语\n",
    "    uatt_span_list = get_u_att(span, seg, pos, dep)\n",
    "    # if uatt_span_list:\n",
    "    #     print('有 uatt', seg[span[0]-1:span[1]])\n",
    "    for uatt_span in uatt_span_list:\n",
    "        start = uatt_span[0]\n",
    "        end = uatt_span[1]\n",
    "        flag = is_isolated_uatt(uatt_span, seg, pos, dep, dep_T2H)\n",
    "        if flag: \n",
    "            print('275 孤立定语', flag, seg[start-1:end])\n",
    "            del_indic[start-1:end+1] = [True]*(end-start+2)\n",
    "            ellip_dic[end+2]['uatt'] = [start, end]\n",
    "    # 去掉无用的“等”\n",
    "    if seg[span[-1]-1]=='等':\n",
    "        del_indic[span[-1]-1] = True\n",
    "        print('138 无用的等', del_indic[span[-1]-1], seg[span[-1]-1])\n",
    "\n",
    "def distill_2(span, seg, pos, dep, dep_T2H, del_indic, ellip_dic):\n",
    "    '''\n",
    "    去掉广义短vatt\n",
    "    以每个词自己为坐标原点向前找svatt的范围\n",
    "    '''\n",
    "    for i in range(span[0]-1, span[1]):\n",
    "        gsvatt_span = get_general_short_vatt(i, pos, dep, dep_T2H)\n",
    "        if gsvatt_span:\n",
    "            start, end = gsvatt_span\n",
    "            del_indic[start-1:end] = [True]*(end-start+1)\n",
    "            print('293 短定语', i, seg[start-1:end])\n",
    "            ellip_dic[i]['svatt'] = gsvatt_span\n",
    "\n",
    "def distill_3(span, seg, pos, dep, dep_T2H, del_indic, ellip_dic):\n",
    "    '''\n",
    "    连续并列合并\n",
    "    '''\n",
    "    # 合并连续短并列\n",
    "    short_coo_spans = get_continum_short_coord_span(span, seg, dep_T2H)\n",
    "    for coo_span in short_coo_spans:\n",
    "        start, end = coo_span\n",
    "        del_indic[start:end] = [True]*(end-start)\n",
    "        ellip_dic[start]['scoo'] = [start+1, end]\n",
    "\n",
    "def exec_dis_func(txt, idx, inter_cache):\n",
    "    '''\n",
    "    在句子的语境下分析一个片段内的并列情况\n",
    "    去掉“的”引导的孤立定语\n",
    "    去掉“ATT”引导短定语-没有出边且父节点不是定语\n",
    "    去掉无用的“等”\n",
    "    连续并列合并\n",
    "    '''\n",
    "    seg, pos, dep = get_spd(txt)\n",
    "    dep_T2H = build_T2H(dep)\n",
    "    so_spans = KPR.get_so(seg, pos, dep, dep_T2H)\n",
    "    del_indic = [False] * len(seg)\n",
    "    ellip_dic = defaultdict(dict)\n",
    "    distill_func = globals()[f'distill_{idx}']\n",
    "    for span in so_spans:\n",
    "        distill_func(span, seg, pos, dep, dep_T2H, del_indic, ellip_dic)\n",
    "    new_txt = [seg[i] for i in range(len(seg)) if not del_indic[i]]\n",
    "    new_txt = ''.join(new_txt)\n",
    "    inter_cache[f'distill_{idx}'] = {\n",
    "        'seg':seg, 'del_indic':del_indic, 'ellip_dic':ellip_dic\n",
    "    }\n",
    "    return new_txt\n",
    "\n",
    "def get_spd(txt):\n",
    "    txt, recover_dic = deal_miss_word(txt, replace_dic)\n",
    "    # print('333', txt)\n",
    "    result = ltp.pipeline([txt], tasks = [\"cws\",\"dep\",\"pos\"])\n",
    "    seg = result.cws[0]\n",
    "    pos = result.pos[0]\n",
    "    dep = result.dep[0]\n",
    "    for key in recover_dic:\n",
    "        seg[key] = recover_dic[key]\n",
    "    dep = list(zip(range(1,1+len(seg)), dep['head'], dep['label']))\n",
    "    return seg, pos, dep\n",
    "\n",
    "txts = [\n",
    "    # '原料库房与设备间（3）均应有保持良好通风的设备，换气次数应为（8~12）次/h',\n",
    "    # '基坑工程、边坡工程设计时，应根据支护（挡）结构破坏可能产生的后果（危及人的生命、造成经济损失、对社会或环境产生影响等）的严重性，采用不同的安全等级。',\n",
    "    # '支护（挡）结构安全等级的划分应符合表 2.2.4 的规定。',\n",
    "    # '所有建（构）筑物的地基计算均应满足承载力要求；',\n",
    "    # '当温度大于30，湿度大于50时，我们要保证体育场打开抽湿器，关闭加热器',\n",
    "    # '给水厂的设计规模应满足供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求',\n",
    "    # '保养厂应能承担营运车辆的高级保养任务及相应的配件加工、修制和修车材料、燃料的储存、发放等',\n",
    "    '保养厂应能承担高级保养任务及相应的配件加工、修制和修车材料、燃料的储存',\n",
    "    # '保养厂应能承担高级保养任务及相应的配件加工、修制和修车材料、燃料的储存',\n",
    "    # '控制中心应具备行车调度、电力调度、环境与设备调度、防灾指挥、客运管理、乘客信息管理、设备维修及信息管理等运营调度和指挥功能，并应对城市轨道交通系统运营的全过程进行集中监控和管理',\n",
    "    # '给水厂应对制水生产中的主要设施、设备制定和实施巡查维护保养制度，应对主要工艺运行情况及其运行中的动态技术参数，制定和实施质量控制点检验制度',\n",
    "    # '建筑无法设置泄压设施或泄压面积不符合要求时，建筑中存在可燃气体、蒸气、粉尘或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。',\n",
    "    # '建筑中存在可燃气体、蒸气、粉尘或纤维爆炸危险的部位的建筑承重结构应满足抗爆要求。',\n",
    "]\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "# %aimport KPR\n",
    "import KPR\n",
    "word_sim = TxtSim(wv_from_text_word, jieba, sbert)\n",
    "k_spliter = KPR.WordSpliter(ltp, word_sim)\n",
    "\n",
    "for txt in txts:\n",
    "    inter_cache = {}\n",
    "    # 文本预处理\n",
    "    seg, pos, dep = get_spd(txt)\n",
    "    new_txt = del_brackets(txt, seg, pos, dep)\n",
    "    if new_txt != txt:\n",
    "        seg, pos, dep = get_spd(new_txt)\n",
    "    print('368', new_txt)\n",
    "    dep_T2H = build_T2H(dep)\n",
    "    del_indic = [False] * len(seg)\n",
    "    ellip_dic = defaultdict(dict)\n",
    "    distill_0(None, seg, pos, dep, dep_T2H, del_indic, ellip_dic)\n",
    "    new_txt = [seg[i] for i in range(len(seg)) if not del_indic[i]]\n",
    "    new_txt = ''.join(new_txt)\n",
    "    inter_cache['distill_0'] = {\n",
    "        'seg':seg, 'del_indic':del_indic, 'ellip_dic':ellip_dic\n",
    "    }\n",
    "    \n",
    "    # 渐进三步走\n",
    "    for idx in [1,2,3]:\n",
    "        print('380', new_txt)\n",
    "        new_txt = exec_dis_func(new_txt, idx, inter_cache)\n",
    "    print('382', new_txt)\n",
    "    print('393 inter_cache', inter_cache)\n",
    "\n",
    "    seg, pos, dep = rule_ner.get_spd(new_txt)\n",
    "    dep_T2H = build_T2H(dep)\n",
    "    so_spans = KPR.get_so(seg, pos, dep, dep_T2H)\n",
    "    show_spd(seg, pos, dep, tag='401')\n",
    "    for span in so_spans:\n",
    "        txt = ''.join(seg[span[0]-1:span[1]])\n",
    "        ent_span, ent_list, incl_tri = k_spliter.split_ent(txt,[],[],[])\n",
    "    print('405', ent_span)\n",
    "    print('406', ent_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from gensim.models import KeyedVectors\n",
    "from model_TS import TxtSim\n",
    "word_vec_tenc = 'D:\\Download\\ArchData\\data\\PreData\\\\arch-zh-d200-tencent-tp200.txt'\n",
    "wv_from_text_word = KeyedVectors.load_word2vec_format(\n",
    "    word_vec_tenc, binary=False, no_header=False)\n",
    "\n",
    "from text2vec import SBert\n",
    "sbert = SBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "238+176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "261 供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
      "[['', '供水范围规定']] []\n",
      "261 综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求\n",
      "[['综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的', '要求']] [['', '综合']]\n",
      "261 综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量\n",
      "[['', '综合']] []\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import model_Spliter\n",
    "word_sim = TxtSim(wv_from_text_word, jieba, sbert)\n",
    "WordSpliter = model_Spliter.WordSpliter\n",
    "txts = [\n",
    "    '非水溶性液体外浮顶储罐、内浮顶储罐、直径大于18m的固定顶储罐及水溶性甲、乙、丙类液体立式储罐',\n",
    "    '高架仓库或高层仓库',\n",
    "    '设备机房、电梯机房、水箱间、天线等突出物',\n",
    "    '国道、省道等干线公路及快速路等道路',\n",
    "    '儿童活动场所、老年人照料设施中的老年人活动场所、医疗建筑中的治疗室和病房、教学建筑中的教学用房',\n",
    "    '医疗建筑中的治疗室和病房',\n",
    "    '地下室的底板、外墙以及上部有覆土的地下室顶板',\n",
    "    '生产过程中散发的可燃气体、蒸气、粉尘或纤维与供暖管道、散热器表面接触能引起燃烧的场所',\n",
    "    '国道、省道等干线公路及快速路等道路',\n",
    "    '配件加工、修制和修车材料、燃料的储存、发放',\n",
    "    '乙、丙、丁、戊类仓库、民用建筑',\n",
    "    '入侵和紧急报警系统、视频监控系统、出入口控制系统、停车库（场）安全管理系统',\n",
    "    '客运管理、乘客信息管理、设备维修及信息管理等运营调度和指挥功能',\n",
    "    '修车材料、燃料的储存、发放',\n",
    "    '住宅建筑内的汽车库、锅炉房和建筑中的下列场所',\n",
    "]\n",
    "txts = [\n",
    "    '供水范围规定年限内最高日的综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求',\n",
    "    '综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量的要求',\n",
    "    '综合生活用水量、工业企业用水量、浇洒道路和绿地用水量、管网漏损水量及未预见用水量'\n",
    "]\n",
    "ent_spliter = WordSpliter(ltp, word_sim)\n",
    "for txt in txts:\n",
    "    print('261',txt)\n",
    "    a,b,c=ent_spliter.split_ent(txt,[],[],[])\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 , 0.5710485 ],\n",
       "       [0.5710485 , 0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_a = ['综合生活用水量','工业企业用水量','浇洒道路','绿地用水量','管网漏损水量','未预见用水量']\n",
    "txt_a = ['地下水质量标准中Ⅰ', 'II类']\n",
    "txt_a = ['非水溶性液体外浮顶储罐','内浮顶储罐','直径大于18m的固定顶储罐','水溶性甲','乙','丙类液体立式储罐']\n",
    "txt_a = ['场所','场所','治疗室','病房']\n",
    "'配件加工、修制和修车材料、燃料'\n",
    "txt_a = ['加工','修制','材料','燃料']\n",
    "txt_a = ['甲','乙','丙']\n",
    "txt_a = ['I','II','类']\n",
    "txt_a = ['底板','外墙']\n",
    "word_sim.cos_sim(txt_a, txt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 类别应划为\n",
      "城乡给水工程主要设施的抗震设防类别应划为重点设防类。\n",
      "38 检测应按国家规定的标准检验方法执行\n",
      "水质检测应按国家规定的标准检验方法执行。\n",
      "38 用水量应根据生产工艺要求确定\n",
      "工业企业用水量应根据生产工艺要求确定，不得超过国家规定的取用水定额限值。\n",
      "38 高程也应按江心式、岸边式取水泵房的防洪标准设计\n",
      "水库取水构筑物的防洪标准应与水库大坝等主要建筑物的防洪标准相同，并应采用设计和校核两级标准。岸上取水泵房采用开放式前池和吸水井（进水池）时，井（池）顶高程也应按江心式、岸边式取水泵房的防洪标准设计。\n",
      "38 位置应根据给水系统的布局确定\n",
      "城乡给水厂的位置应根据给水系统的布局确定。\n",
      "38 泥水、浮渣、废水和废液均应进行\n",
      "水处理过程中产生的泥水、浮渣、废水和废液均应进行处理处置，严禁擅自直接排入环境水体。\n",
      "38 参数应按事故工况计算\n",
      "水处理构筑物及连接管渠的设计参数应按事故工况计算校核。\n",
      "38 药剂必须计量投加\n",
      "水处理药剂必须计量投加。\n",
      "38 合格方可使用\n",
      "化验室所用的计量分析仪器必须定期进行计量检定，经检定合格方可使用。计量分析仪器在日常使用过程中应定期进行校准和维护。\n",
      "38 房间应相互隔\n",
      "各个房间应相互隔开，室内应互不连通；\n",
      "38 \n",
      "二氧化氯发生与投加设备间应配备二氧化氯泄漏的低、高检测极限检测仪和报警设施，室内应设喷淋装置。\n",
      "38 水锤综合防护\n",
      "长距离管道输水系统的选择应在输水线路、输水方式、管材、管径等方面进行技术、经济比较和安全论证，并应对管道系统进行水力过渡过程分析，采取水锤综合防护措施。\n",
      "38 管线综合布置\n",
      "城乡给水管道的平面布置和竖向位置，应保证供水安全，与建（构）筑物及其他管线的安全防护距离应符合国家规定的管线综合布置的要求。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import dic_read_csv\n",
    "\n",
    "def get_all_uatt_in_txt(txt):\n",
    "    seg, pos, dep = rule_ner.get_spd(txt)\n",
    "    new_txt = del_brackets(txt, seg, pos, dep)\n",
    "    if new_txt:\n",
    "        seg, pos, dep = rule_ner.get_spd(new_txt)\n",
    "    else:\n",
    "        new_txt = txt\n",
    "    uatt_spans = get_u_att([1,len(seg)], seg, pos, dep)\n",
    "    return uatt_spans\n",
    "\n",
    "csv_path = 'D:\\Download\\ArchData\\data\\Corpus\\csv_'\n",
    "csv_list = os.listdir(csv_path)\n",
    "all_ahp = []\n",
    "all_uatts = []\n",
    "for name in csv_list:\n",
    "    if '1城乡' not in name: continue\n",
    "    file_name = os.path.join(csv_path, name)\n",
    "    file_dic = dic_read_csv(file_name)\n",
    "    idx_list = file_dic['编号']\n",
    "    txt_list = file_dic['原文']\n",
    "    for i in range(len(idx_list)):\n",
    "        if idx_list[i] and idx_list[i][0] not in '表注':\n",
    "            # ahp = rule_ner.get_att_head_phrase(txt_list[i])\n",
    "            # all_ahp += ahp\n",
    "            txt = txt_list[i]\n",
    "            seg, pos, dep = rule_ner.get_spd(txt)\n",
    "            new_txt = del_brackets(txt, seg, pos, dep)\n",
    "            if new_txt:\n",
    "                seg, pos, dep = rule_ner.get_spd(new_txt)\n",
    "            else:\n",
    "                new_txt = txt\n",
    "            uatt_spans = get_u_att([1,len(seg)], seg, pos, dep)\n",
    "            flag = False\n",
    "            for d in dep:\n",
    "                if d[2]=='FOB' and d[1]-d[0]==1: \n",
    "                    continue\n",
    "                    flag = True\n",
    "                    print('38', ''.join(seg[d[0]-1:d[1]]))\n",
    "                elif d[2]=='FOB':\n",
    "                    flag = True\n",
    "                    print('38', ''.join(seg[d[0]-1:d[1]]))\n",
    "            if flag: print(txt)\n",
    "            # print(uatt_spans)\n",
    "            uatts = [''.join(seg[s[0]-1:s[1]]) for s in uatt_spans]\n",
    "            all_uatts += uatts\n",
    "# print(all_ahp)\n",
    "# print(all_uatts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc293f25d9b2e08ed2fd720b85589440a3807ec86f7cee2822a6b1ce149b10db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
